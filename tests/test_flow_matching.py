"""
Flow Matching åŠŸèƒ½æµ‹è¯•è„šæœ¬

æµ‹è¯•FMæ¨¡å‹ã€è·¯å¾„ã€æ±‚è§£å™¨å’Œå¼•å¯¼æ¨¡å—çš„åŸºæœ¬åŠŸèƒ½
"""

import torch
import sys
sys.path.insert(0, '/home/xiantuo/source/grasp/GithubClone/SceneLeapUltra')

def test_imports():
    """æµ‹è¯•æ‰€æœ‰FMæ¨¡å—æ˜¯å¦èƒ½æ­£ç¡®å¯¼å…¥"""
    print("æµ‹è¯•1: æ¨¡å—å¯¼å…¥")
    try:
        from models.decoder.dit_fm import DiTFM, ContinuousTimeEmbedding
        from models.fm_lightning import FlowMatchingLightning
        from models.fm.paths import linear_ot_path, diffusion_path_vp
        from models.fm.solvers import heun_solver, rk4_solver, integrate_ode
        from models.fm.guidance import apply_cfg, apply_cfg_clipped
        print("âœ… æ‰€æœ‰æ¨¡å—å¯¼å…¥æˆåŠŸ")
        return True
    except Exception as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_continuous_time_embedding():
    """æµ‹è¯•è¿ç»­æ—¶é—´åµŒå…¥"""
    print("\næµ‹è¯•2: ContinuousTimeEmbedding")
    try:
        from models.decoder.dit_fm import ContinuousTimeEmbedding
        
        B = 4
        dim = 512
        freq_dim = 256
        
        embed = ContinuousTimeEmbedding(dim, freq_dim)
        t = torch.rand(B)  # [0, 1]
        
        emb = embed(t)
        
        assert emb.shape == (B, dim), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {emb.shape}"
        assert not torch.isnan(emb).any(), "è¾“å‡ºåŒ…å«NaN"
        assert not torch.isinf(emb).any(), "è¾“å‡ºåŒ…å«Inf"
        
        print(f"âœ… è¿ç»­æ—¶é—´åµŒå…¥æµ‹è¯•é€šè¿‡")
        print(f"   è¾“å…¥: t={t.shape}, è¾“å‡º: emb={emb.shape}")
        print(f"   èŒƒå›´: [{emb.min():.3f}, {emb.max():.3f}]")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_linear_ot_path():
    """æµ‹è¯•çº¿æ€§OTè·¯å¾„"""
    print("\næµ‹è¯•3: Linear OT Path")
    try:
        from models.fm.paths import linear_ot_path
        
        B, num_grasps, D = 2, 4, 25
        x0 = torch.randn(B, num_grasps, D)
        x1 = torch.randn(B, num_grasps, D)
        t = torch.rand(B)
        
        x_t, v_star = linear_ot_path(x0, x1, t)
        
        assert x_t.shape == (B, num_grasps, D), f"x_tå½¢çŠ¶é”™è¯¯: {x_t.shape}"
        assert v_star.shape == (B, num_grasps, D), f"v_starå½¢çŠ¶é”™è¯¯: {v_star.shape}"
        
        # éªŒè¯é€Ÿåº¦æ˜¯å¸¸é‡
        v_expected = x1 - x0
        assert torch.allclose(v_star, v_expected, atol=1e-6), "é€Ÿåº¦è®¡ç®—é”™è¯¯"
        
        # éªŒè¯æ’å€¼
        t_exp = t.view(-1, 1, 1)
        x_t_expected = (1 - t_exp) * x0 + t_exp * x1
        assert torch.allclose(x_t, x_t_expected, atol=1e-6), "æ’å€¼è®¡ç®—é”™è¯¯"
        
        print(f"âœ… Linear OT Pathæµ‹è¯•é€šè¿‡")
        print(f"   x0: {x0.shape}, x1: {x1.shape}, t: {t.shape}")
        print(f"   x_t: {x_t.shape}, v_star: {v_star.shape}")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_rk4_solver():
    """æµ‹è¯•RK4æ±‚è§£å™¨"""
    print("\næµ‹è¯•4: RK4 Solver")
    try:
        from models.fm.solvers import rk4_solver, ODESolverStats
        
        B, num_grasps, D = 2, 4, 25
        
        # ç®€å•çš„å¸¸é€Ÿåº¦åœº v(x, t) = constant
        def constant_velocity_fn(x, t, data):
            return torch.ones_like(x) * 0.1
        
        x1 = torch.randn(B, num_grasps, D)
        data = {}
        stats = ODESolverStats()
        
        x0, info = rk4_solver(constant_velocity_fn, x1, data, nfe=32, stats=stats)
        
        assert x0.shape == (B, num_grasps, D), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {x0.shape}"
        assert not torch.isnan(x0).any(), "è¾“å‡ºåŒ…å«NaN"
        assert info['solver'] == 'rk4', "æ±‚è§£å™¨ç±»å‹é”™è¯¯"
        assert stats.nfe == 32, f"NFEé”™è¯¯: {stats.nfe}"
        
        print(f"âœ… RK4æ±‚è§£å™¨æµ‹è¯•é€šè¿‡")
        print(f"   NFE: {stats.nfe}, æ­¥æ•°: {stats.accepted_steps}")
        print(f"   è¾“å…¥: {x1.shape}, è¾“å‡º: {x0.shape}")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_cfg_clipped():
    """æµ‹è¯•è£å‰ªCFG"""
    print("\næµ‹è¯•5: CFG Clipped")
    try:
        from models.fm.guidance import apply_cfg_clipped
        
        B, num_grasps, D = 2, 4, 25
        v_cond = torch.randn(B, num_grasps, D)
        v_uncond = torch.randn(B, num_grasps, D)
        
        scale = 3.0
        clip_norm = 5.0
        
        v_cfg = apply_cfg_clipped(v_cond, v_uncond, scale, clip_norm)
        
        assert v_cfg.shape == (B, num_grasps, D), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {v_cfg.shape}"
        assert not torch.isnan(v_cfg).any(), "è¾“å‡ºåŒ…å«NaN"
        
        # éªŒè¯è£å‰ªæ•ˆæœ
        diff = v_cond - v_uncond
        diff_norm = torch.norm(diff, dim=-1)
        
        print(f"âœ… CFG Clippedæµ‹è¯•é€šè¿‡")
        print(f"   v_cond: {v_cond.shape}, v_uncond: {v_uncond.shape}")
        print(f"   å·®å¼‚èŒƒæ•°: min={diff_norm.min():.3f}, max={diff_norm.max():.3f}")
        print(f"   CFGè¾“å‡º: {v_cfg.shape}")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_dit_fm_forward():
    """æµ‹è¯•DiT-FMå‰å‘ä¼ æ’­"""
    print("\næµ‹è¯•6: DiT-FM Forward (éœ€è¦GPU)")
    
    # Skip test on CPU (PointNet2 requires CUDA)
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True)
        has_gpu = (result.returncode == 0)
    except:
        has_gpu = False
    
    if not has_gpu:
        print("âš ï¸  è·³è¿‡æµ‹è¯•ï¼ˆPointNet2éœ€è¦GPUï¼ŒCPUç¯å¢ƒè‡ªåŠ¨è·³è¿‡ï¼‰")
        return True
    
    try:
        from omegaconf import OmegaConf
        from models.decoder.dit_fm import DiTFM
        
        # åˆ›å»ºæœ€å°é…ç½®
        cfg = OmegaConf.create({
            'name': 'dit_fm',
            'mode': 'velocity',
            'rot_type': 'r6d',
            'd_model': 256,
            'num_layers': 2,
            'num_heads': 4,
            'd_head': 64,
            'dropout': 0.1,
            'max_sequence_length': 100,
            'use_learnable_pos_embedding': False,
            'time_embed_dim': 512,
            'use_adaptive_norm': True,
            'continuous_time': True,
            'freq_dim': 128,
            'use_text_condition': False,
            'text_dropout_prob': 0.1,
            'use_negative_prompts': False,
            'use_object_mask': False,
            'use_rgb': False,
            'backbone': {
                'name': 'pointnet2',
                'use_pooling': False,
                'layer1': {
                    'npoint': 512,
                    'radius_list': [0.04],
                    'nsample_list': [32],
                    'mlp_list': [0, 64, 64, 128]
                },
                'layer2': {
                    'npoint': 256,
                    'radius_list': [0.1],
                    'nsample_list': [16],
                    'mlp_list': [128, 128, 128, 256]
                },
                'layer3': {
                    'npoint': 128,
                    'radius_list': [0.2],
                    'nsample_list': [16],
                    'mlp_list': [256, 128, 128, 256]
                },
                'layer4': {
                    'npoint': 64,
                    'radius_list': [0.3],
                    'nsample_list': [8],
                    'mlp_list': [256, 512, 512]
                },
                'use_xyz': True,
                'normalize_xyz': True
            },
            'debug': {
                'check_nan': True,
                'log_tensor_stats': False
            }
        })
        
        model = DiTFM(cfg)
        model.eval()
        model = model.cuda()
        
        B, num_grasps, D = 2, 4, 25
        x_t = torch.randn(B, num_grasps, D).cuda()
        t = torch.rand(B).cuda()
        
        # æœ€å°æ•°æ®å­—å…¸
        data = {
            'scene_pc': torch.randn(B, 1024, 3).cuda(),
        }
        
        # é¢„è®¡ç®—æ¡ä»¶
        cond = model.condition(data)
        data.update(cond)
        
        # å‰å‘ä¼ æ’­
        with torch.no_grad():
            v_pred = model(x_t, t, data)
        
        assert v_pred.shape == (B, num_grasps, D), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {v_pred.shape}"
        assert not torch.isnan(v_pred).any(), "è¾“å‡ºåŒ…å«NaN"
        assert not torch.isinf(v_pred).any(), "è¾“å‡ºåŒ…å«Inf"
        
        print(f"âœ… DiT-FMå‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
        print(f"   è¾“å…¥: x_t={x_t.shape}, t={t.shape}")
        print(f"   è¾“å‡º: v_pred={v_pred.shape}")
        print(f"   èŒƒå›´: [{v_pred.min():.3f}, {v_pred.max():.3f}]")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*60)
    print("Flow Matching åŠŸèƒ½æµ‹è¯•")
    print("="*60)
    
    tests = [
        ("æ¨¡å—å¯¼å…¥", test_imports),
        ("è¿ç»­æ—¶é—´åµŒå…¥", test_continuous_time_embedding),
        ("Linear OTè·¯å¾„", test_linear_ot_path),
        ("RK4æ±‚è§£å™¨", test_rk4_solver),
        ("CFGè£å‰ª", test_cfg_clipped),
        ("DiT-FMå‰å‘", test_dit_fm_forward),
    ]
    
    results = []
    for name, test_fn in tests:
        try:
            result = test_fn()
            results.append((name, result))
        except Exception as e:
            print(f"\nâŒ {name} æ‰§è¡Œå¼‚å¸¸: {e}")
            results.append((name, False))
    
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {name}")
    
    print(f"\né€šè¿‡ç‡: {passed}/{total} ({100*passed/total:.1f}%)")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Flow MatchingåŸºç¡€åŠŸèƒ½æ­£å¸¸ã€‚")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed}ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°ã€‚")
        return 1


if __name__ == "__main__":
    exit(main())

