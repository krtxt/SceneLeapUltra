"""
æµ‹è¯• Optimal Transport åŠŸèƒ½

è¿è¡Œæ–¹å¼ï¼š
    cd /home/xiantuo/source/grasp/GithubClone/SceneLeapUltra
    source ~/.bashrc && conda activate DexGrasp
    python tests/test_optimal_transport.py
"""

import sys
import os
import torch
import logging
import matplotlib.pyplot as plt
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from models.fm.optimal_transport import (
    SinkhornOT, 
    apply_optimal_matching,
    compute_matching_quality,
    sinkhorn_matching
)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(message)s')


def test_basic_ot():
    """æµ‹è¯•åŸºæœ¬çš„OTåŠŸèƒ½"""
    print("\n" + "="*60)
    print("æµ‹è¯• 1: åŸºæœ¬ Sinkhorn OT åŠŸèƒ½")
    print("="*60)
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    B, N, D = 4, 128, 25
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    x0 = torch.randn(B, N, D, device=device)
    x1 = torch.randn(B, N, D, device=device)
    
    print(f"æ•°æ®å½¢çŠ¶: x0={x0.shape}, x1={x1.shape}")
    print(f"è®¾å¤‡: {device}")
    
    # åˆ›å»ºOTæ±‚è§£å™¨
    ot_solver = SinkhornOT(
        reg=0.1,
        num_iters=50,
        distance_metric='euclidean',
        matching_strategy='greedy',
    )
    
    # è®¡ç®—é…å¯¹
    print("\næ­£åœ¨è®¡ç®—æœ€ä¼˜é…å¯¹...")
    matchings, info = ot_solver(x0, x1, return_info=True)
    
    print(f"âœ… é…å¯¹å®Œæˆï¼")
    print(f"  - é…å¯¹ç´¢å¼•å½¢çŠ¶: {matchings.shape}")
    print(f"  - åŸå§‹å¹³å‡è·ç¦»: {info['random_distance']:.4f}")
    print(f"  - é…å¯¹åå¹³å‡è·ç¦»: {info['matched_distance']:.4f}")
    print(f"  - æ”¹è¿›ç™¾åˆ†æ¯”: {info['improvement']:.1f}%")
    
    # éªŒè¯é…å¯¹
    x1_matched = apply_optimal_matching(x0, x1, matchings)
    quality = compute_matching_quality(x0, x1, x1_matched)
    
    print(f"\né…å¯¹è´¨é‡ç»Ÿè®¡:")
    print(f"  - å¹³å‡è·ç¦»å‡å°‘: {quality['improvement_percent']:.1f}%")
    print(f"  - æœ€å°è·ç¦»: {quality['min_dist_matched']:.4f}")
    print(f"  - æœ€å¤§è·ç¦»: {quality['max_dist_matched']:.4f}")
    
    assert matchings.shape == (B, N), "é…å¯¹ç´¢å¼•å½¢çŠ¶é”™è¯¯"
    assert info['matched_distance'] < info['random_distance'], "OTåº”è¯¥å‡å°‘å¹³å‡è·ç¦»"
    
    print("\nâœ… æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_different_configs():
    """æµ‹è¯•ä¸åŒçš„é…ç½®å‚æ•°"""
    print("\n" + "="*60)
    print("æµ‹è¯• 2: ä¸åŒé…ç½®å‚æ•°çš„å½±å“")
    print("="*60)
    
    B, N, D = 2, 64, 25
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    x0 = torch.randn(B, N, D, device=device)
    x1 = torch.randn(B, N, D, device=device)
    
    configs = [
        {'reg': 0.05, 'num_iters': 50, 'desc': 'ä½æ­£åˆ™åŒ–ï¼ˆæ›´ç²¾ç¡®ï¼‰'},
        {'reg': 0.1, 'num_iters': 50, 'desc': 'ä¸­ç­‰æ­£åˆ™åŒ–ï¼ˆå¹³è¡¡ï¼‰'},
        {'reg': 0.2, 'num_iters': 50, 'desc': 'é«˜æ­£åˆ™åŒ–ï¼ˆæ›´å¿«ï¼‰'},
        {'reg': 0.1, 'num_iters': 20, 'desc': 'å°‘è¿­ä»£æ¬¡æ•°'},
        {'reg': 0.1, 'num_iters': 100, 'desc': 'å¤šè¿­ä»£æ¬¡æ•°'},
    ]
    
    results = []
    for cfg in configs:
        ot_solver = SinkhornOT(
            reg=cfg['reg'],
            num_iters=cfg['num_iters'],
            distance_metric='euclidean'
        )
        
        matchings, info = ot_solver(x0, x1, return_info=True)
        results.append({
            'config': cfg['desc'],
            'reg': cfg['reg'],
            'iters': cfg['num_iters'],
            'matched_dist': info['matched_distance'],
            'improvement': info['improvement']
        })
        
        print(f"{cfg['desc']:30s}: "
              f"matched_dist={info['matched_distance']:.4f}, "
              f"improvement={info['improvement']:.1f}%")
    
    print("\nâœ… æµ‹è¯•é€šè¿‡ï¼")
    return results


def test_batch_sizes():
    """æµ‹è¯•ä¸åŒbatch sizeå’Œgraspæ•°é‡"""
    print("\n" + "="*60)
    print("æµ‹è¯• 3: ä¸åŒæ•°æ®è§„æ¨¡çš„æ€§èƒ½")
    print("="*60)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    D = 25
    
    test_cases = [
        (4, 64, "å°è§„æ¨¡"),
        (8, 128, "ä¸­è§„æ¨¡"),
        (16, 256, "å¤§è§„æ¨¡"),
        (32, 512, "è¶…å¤§è§„æ¨¡"),
    ]
    
    ot_solver = SinkhornOT(reg=0.1, num_iters=50)
    
    for B, N, desc in test_cases:
        x0 = torch.randn(B, N, D, device=device)
        x1 = torch.randn(B, N, D, device=device)
        
        # æµ‹é€Ÿ
        if device == 'cuda':
            torch.cuda.synchronize()
        
        import time
        start = time.time()
        matchings, info = ot_solver(x0, x1, return_info=True)
        
        if device == 'cuda':
            torch.cuda.synchronize()
        elapsed = time.time() - start
        
        print(f"{desc:15s} [B={B:2d}, N={N:4d}]: "
              f"æ—¶é—´={elapsed*1000:.2f}ms, "
              f"æ”¹è¿›={info['improvement']:.1f}%")
    
    print("\nâœ… æµ‹è¯•é€šè¿‡ï¼")
    return True


def test_visualization():
    """å¯è§†åŒ–é…å¯¹æ•ˆæœï¼ˆ2DæŠ•å½±ï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯• 4: å¯è§†åŒ–é…å¯¹æ•ˆæœ")
    print("="*60)
    
    # åˆ›å»º2Dæ•°æ®ä¾¿äºå¯è§†åŒ–
    B, N, D = 1, 100, 2
    device = 'cpu'  # å¯è§†åŒ–ç”¨CPU
    
    # åˆ›å»ºä¸¤ä¸ªèšç±»åˆ†å¸ƒ
    x0 = torch.cat([
        torch.randn(50, 2) * 0.3 + torch.tensor([1.0, 1.0]),
        torch.randn(50, 2) * 0.3 + torch.tensor([-1.0, -1.0]),
    ]).unsqueeze(0)
    
    x1 = torch.randn(1, N, D) * 1.5
    
    # è®¡ç®—é…å¯¹
    ot_solver = SinkhornOT(reg=0.1, num_iters=50)
    matchings, info = ot_solver(x0, x1, return_info=True)
    x1_matched = apply_optimal_matching(x0, x1, matchings)
    
    # ç»˜å›¾
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # å­å›¾1: æ•°æ®åˆ†å¸ƒ
    axes[0].scatter(x0[0, :, 0], x0[0, :, 1], c='blue', alpha=0.6, label='x0 (çœŸå®æŠ“å–)')
    axes[0].scatter(x1[0, :, 0], x1[0, :, 1], c='red', alpha=0.6, label='x1 (åŸå§‹å™ªå£°)')
    axes[0].legend()
    axes[0].set_title('æ•°æ®åˆ†å¸ƒ')
    axes[0].grid(True, alpha=0.3)
    
    # å­å›¾2: éšæœºé…å¯¹
    axes[1].scatter(x0[0, :, 0], x0[0, :, 1], c='blue', alpha=0.6, s=20)
    axes[1].scatter(x1[0, :, 0], x1[0, :, 1], c='red', alpha=0.6, s=20)
    for i in range(0, N, 5):  # åªç”»éƒ¨åˆ†çº¿é¿å…å¤ªå¯†
        axes[1].plot([x0[0, i, 0], x1[0, i, 0]], 
                     [x0[0, i, 1], x1[0, i, 1]], 
                     'gray', alpha=0.3, linewidth=0.5)
    axes[1].set_title(f'éšæœºé…å¯¹\nå¹³å‡è·ç¦»: {info["random_distance"]:.3f}')
    axes[1].grid(True, alpha=0.3)
    
    # å­å›¾3: OTé…å¯¹
    axes[2].scatter(x0[0, :, 0], x0[0, :, 1], c='blue', alpha=0.6, s=20)
    axes[2].scatter(x1_matched[0, :, 0], x1_matched[0, :, 1], c='red', alpha=0.6, s=20)
    for i in range(0, N, 5):
        axes[2].plot([x0[0, i, 0], x1_matched[0, i, 0]], 
                     [x0[0, i, 1], x1_matched[0, i, 1]], 
                     'green', alpha=0.5, linewidth=0.8)
    axes[2].set_title(f'OTé…å¯¹\nå¹³å‡è·ç¦»: {info["matched_distance"]:.3f}\næ”¹è¿›: {info["improvement"]:.1f}%')
    axes[2].grid(True, alpha=0.3)
    
    plt.tight_layout()
    save_path = 'tests/ot_visualization.png'
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"âœ… å¯è§†åŒ–å·²ä¿å­˜åˆ°: {save_path}")
    
    # å¦‚æœä¸åœ¨æœåŠ¡å™¨ç¯å¢ƒï¼Œå¯ä»¥æ˜¾ç¤ºå›¾åƒ
    # plt.show()
    
    return True


def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦ä¼ æ’­ï¼ˆç¡®ä¿å¯å¾®åˆ†ï¼‰"""
    print("\n" + "="*60)
    print("æµ‹è¯• 5: æ¢¯åº¦ä¼ æ’­")
    print("="*60)
    
    B, N, D = 2, 32, 25
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    x0 = torch.randn(B, N, D, device=device, requires_grad=True)
    x1 = torch.randn(B, N, D, device=device, requires_grad=True)
    
    ot_solver = SinkhornOT(reg=0.1, num_iters=30)
    matchings = ot_solver(x0, x1, return_info=False)
    
    # åº”ç”¨é…å¯¹å¹¶è®¡ç®—æŸå¤±
    x1_matched = apply_optimal_matching(x0, x1, matchings)
    loss = torch.nn.functional.mse_loss(x0, x1_matched)
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    print(f"æŸå¤±: {loss.item():.4f}")
    print(f"x0æ¢¯åº¦èŒƒæ•°: {x0.grad.norm().item():.4f}")
    print(f"x1æ¢¯åº¦èŒƒæ•°: {x1.grad.norm().item():.4f}")
    
    assert x0.grad is not None, "x0åº”è¯¥æœ‰æ¢¯åº¦"
    assert x1.grad is not None, "x1åº”è¯¥æœ‰æ¢¯åº¦"
    assert not torch.isnan(x0.grad).any(), "æ¢¯åº¦ä¸åº”åŒ…å«NaN"
    
    print("âœ… æ¢¯åº¦ä¼ æ’­æ­£å¸¸ï¼")
    return True


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*70)
    print(" "*15 + "Optimal Transport åŠŸèƒ½æµ‹è¯•")
    print("="*70)
    
    tests = [
        ("åŸºæœ¬åŠŸèƒ½", test_basic_ot),
        ("é…ç½®å‚æ•°", test_different_configs),
        ("æ•°æ®è§„æ¨¡", test_batch_sizes),
        ("å¯è§†åŒ–", test_visualization),
        ("æ¢¯åº¦ä¼ æ’­", test_gradient_flow),
    ]
    
    results = []
    for name, test_fn in tests:
        try:
            result = test_fn()
            results.append((name, "âœ… é€šè¿‡", result))
            print()
        except Exception as e:
            results.append((name, f"âŒ å¤±è´¥: {str(e)}", None))
            print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}\n")
            import traceback
            traceback.print_exc()
    
    # æ€»ç»“
    print("\n" + "="*70)
    print("æµ‹è¯•æ€»ç»“:")
    print("="*70)
    for name, status, _ in results:
        print(f"  {name:20s}: {status}")
    
    passed = sum(1 for _, s, _ in results if s.startswith("âœ…"))
    total = len(results)
    print(f"\né€šè¿‡: {passed}/{total}")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ã€‚")
    
    return results


if __name__ == "__main__":
    run_all_tests()

