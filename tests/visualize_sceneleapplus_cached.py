#!/usr/bin/env python3
"""
SceneLeapPlusDatasetCached å¯è§†åŒ–æµ‹è¯•è„šæœ¬
éªŒè¯ä¿®å¤åçš„ç¼“å­˜æ•°æ®é›†ç±»çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ç¼“å­˜æ–‡ä»¶åˆ›å»ºã€æ•°æ®åŠ è½½å’Œå¯è§†åŒ–

ä¸»è¦åŠŸèƒ½ï¼š
1. æµ‹è¯•ä¿®å¤åçš„ SceneLeapPlusDatasetCached ç±»
2. éªŒè¯ç¼“å­˜æ–‡ä»¶çš„åˆ›å»ºå’Œè¯»å–
3. å¯è§†åŒ–6Dç‚¹äº‘ï¼ˆxyz+rgbé¢œè‰²ï¼‰
4. å¯è§†åŒ–å¤šä¸ªLEAPçµå·§æ‰‹æŠ“å–å§¿æ€
5. å¯è§†åŒ–ç›®æ ‡ç‰©ä½“mesh
6. éªŒè¯ä¿®å¤çš„å‚æ•°ï¼ˆsucc_grasp_dir, obj_root_dir, max_grasps_per_objectï¼‰
7. æµ‹è¯•æ­£è´Ÿæç¤ºè¯çš„åŠ è½½
8. æµ‹è¯•å››ç§åæ ‡ç³»ç»Ÿæ¨¡å¼çš„ç¼“å­˜æ•°æ®é›†
9. æ”¯æŒå¤šæŠ“å–å¹¶è¡Œå­¦ä¹ æ¶æ„çš„å¯è§†åŒ–

æ”¯æŒçš„åæ ‡ç³»ç»Ÿæ¨¡å¼ï¼š
- camera_centric: ç›¸æœºåæ ‡ç³»ï¼ˆåŸå§‹ï¼‰
- object_centric: ç‰©ä½“æ¨¡å‹åæ ‡ç³»
- camera_centric_obj_mean_normalized: ç›¸æœºåæ ‡ç³» + ç‰©ä½“ä¸­å¿ƒå½’ä¸€åŒ–
- camera_centric_scene_mean_normalized: ç›¸æœºåæ ‡ç³» + åœºæ™¯ä¸­å¿ƒå½’ä¸€åŒ–

å¯è§†åŒ–ç»„ä»¶ï¼š
- çº¢è‰²ç‚¹äº‘ï¼šç›®æ ‡ç‰©ä½“ç‚¹äº‘ï¼ˆåŸºäºobject_maskï¼‰
- ç°è‰²ç‚¹äº‘ï¼šèƒŒæ™¯ç‚¹äº‘
- ç»¿è‰²meshï¼šç›®æ ‡ç‰©ä½“meshï¼ˆæ¥è‡ªobj_vertså’Œobj_facesï¼‰
- å½©è‰²meshï¼šå¤šä¸ªLEAPæ‰‹éƒ¨meshï¼ˆä¸åŒé¢œè‰²åŒºåˆ†ä¸åŒæŠ“å–ï¼‰
- RGBåæ ‡è½´ï¼šä¸–ç•Œåæ ‡ç³»å‚è€ƒ

SceneLeapPlusDatasetCachedç‰¹æ€§ï¼š
- è¿”å›å›ºå®šæ•°é‡çš„æŠ“å–å§¿æ€ (num_grasps, 23)
- æ”¯æŒå¤šæŠ“å–å¹¶è¡Œå­¦ä¹ æ¶æ„
- HDF5ç¼“å­˜å­˜å‚¨ï¼Œæé«˜æ•°æ®åŠ è½½æ•ˆç‡
- åˆ†å¸ƒå¼è®­ç»ƒæ”¯æŒ
"""

import os
import sys
import torch
import numpy as np
import open3d as o3d
import time
import logging
from typing import Optional, Tuple, Dict, Any, List

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

try:
    from datasets.sceneleapplus_cached import SceneLeapPlusDatasetCached
    from datasets.sceneleapplus_dataset import SceneLeapPlusDataset
    from utils.hand_model import HandModel
    from utils.hand_types import HandModelType
except ImportError as e:
    logger.error(f"å¯¼å…¥é”™è¯¯: {e}")
    sys.exit(1)

# çœŸå®æ•°æ®è·¯å¾„
ROOT_DIR = "/home/xiantuo/source/grasp/SceneLeapPro/data/723_sub_15"
SUCC_GRASP_DIR = "/home/xiantuo/source/grasp/SceneLeapPro/data/succ_collect"
OBJ_ROOT_DIR = "/home/xiantuo/source/grasp/SceneLeapPro/data/object/objaverse_v1/flat_models"

def verify_paths():
    """éªŒè¯æ•°æ®è·¯å¾„æ˜¯å¦å­˜åœ¨"""
    paths = {
        'root_dir': ROOT_DIR,
        'succ_grasp_dir': SUCC_GRASP_DIR,
        'obj_root_dir': OBJ_ROOT_DIR
    }
    
    for name, path in paths.items():
        if os.path.exists(path):
            logger.info(f"âœ… {name}: {path}")
        else:
            logger.error(f"âŒ {name} ä¸å­˜åœ¨: {path}")
            return False
    return True

def test_cached_dataset_creation():
    """æµ‹è¯•ç¼“å­˜æ•°æ®é›†çš„åˆ›å»º"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯• SceneLeapPlusDatasetCached åˆ›å»º")
    logger.info("=" * 60)
    
    try:
        # ä½¿ç”¨å°è§„æ¨¡å‚æ•°è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        logger.info("æ­£åœ¨åˆ›å»ºç¼“å­˜æ•°æ®é›†ï¼ˆå°è§„æ¨¡æµ‹è¯•ï¼‰...")
        start_time = time.time()
        
        cached_dataset = SceneLeapPlusDatasetCached(
            root_dir=ROOT_DIR,
            succ_grasp_dir=SUCC_GRASP_DIR,
            obj_root_dir=OBJ_ROOT_DIR,
            num_grasps=4,  # SceneLeapPlusç‰¹æœ‰å‚æ•°
            mode="camera_centric",
            max_grasps_per_object=2,  # é™åˆ¶æ•°æ®é‡
            mesh_scale=0.1,
            num_neg_prompts=4,
            enable_cropping=True,
            max_points=10000,  # é™åˆ¶ç‚¹äº‘å¤§å°
            grasp_sampling_strategy="random",  # SceneLeapPlusç‰¹æœ‰å‚æ•°
            cache_version="v2.0_plus_test",  # æ›´æ–°ç¼“å­˜ç‰ˆæœ¬
            # ç©·å°½é‡‡æ ·å‚æ•° - å¯ä»¥åœ¨è¿™é‡Œæµ‹è¯•ç©·å°½é‡‡æ ·
            use_exhaustive_sampling=False,  # è®¾ä¸ºTrueå¯æµ‹è¯•ç©·å°½é‡‡æ ·
            exhaustive_sampling_strategy="sequential"  # å¯é€‰ç­–ç•¥
        )
        
        creation_time = time.time() - start_time
        logger.info(f"âœ… ç¼“å­˜æ•°æ®é›†åˆ›å»ºæˆåŠŸï¼")
        logger.info(f"   - æ•°æ®é‡: {len(cached_dataset)}")
        logger.info(f"   - åˆ›å»ºæ—¶é—´: {creation_time:.2f} ç§’")
        logger.info(f"   - æ¯ä¸ªæ ·æœ¬æŠ“å–æ•°é‡: {cached_dataset.num_grasps}")
        
        # è·å–ç¼“å­˜ä¿¡æ¯
        cache_info = cached_dataset.get_cache_info()
        logger.info(f"   - ç¼“å­˜è·¯å¾„: {cache_info['cache_path']}")
        logger.info(f"   - ç¼“å­˜çŠ¶æ€: {'å·²åŠ è½½' if cache_info['cache_loaded'] else 'æœªåŠ è½½'}")
        
        return cached_dataset
        
    except Exception as e:
        logger.error(f"âŒ ç¼“å­˜æ•°æ®é›†åˆ›å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def analyze_sample_data(sample: Dict[str, Any], sample_idx: int):
    """åˆ†ææ ·æœ¬æ•°æ®"""
    logger.info(f"=" * 50)
    logger.info(f"æ ·æœ¬ {sample_idx} æ•°æ®åˆ†æ")
    logger.info(f"=" * 50)
    
    # åŸºæœ¬ä¿¡æ¯
    if 'scene_id' in sample:
        logger.info(f"åœºæ™¯ID: {sample['scene_id']}")
    if 'obj_code' in sample:
        logger.info(f"ç‰©ä½“ä»£ç : {sample['obj_code']}")
    if 'positive_prompt' in sample:
        logger.info(f"æ­£é¢æç¤ºè¯: '{sample['positive_prompt']}'")
    if 'negative_prompts' in sample:
        logger.info(f"è´Ÿé¢æç¤ºè¯: {sample['negative_prompts']}")
    
    # æ•°æ®å½¢çŠ¶åˆ†æ
    logger.info("æ•°æ®å½¢çŠ¶:")
    for key, value in sample.items():
        if isinstance(value, torch.Tensor):
            logger.info(f"  - {key}: {value.shape} ({value.dtype})")
        elif isinstance(value, (list, tuple)):
            logger.info(f"  - {key}: {type(value).__name__}[{len(value)}]")
        else:
            logger.info(f"  - {key}: {type(value).__name__}")
    
    # éªŒè¯SceneLeapPlusç‰¹æœ‰åŠŸèƒ½
    logger.info("SceneLeapPlusç‰¹æ€§éªŒè¯:")
    
    # æ£€æŸ¥å¤šæŠ“å–æ•°æ®
    if 'hand_model_pose' in sample:
        hand_pose = sample['hand_model_pose']
        print("hand_pose : " , hand_pose)
        if isinstance(hand_pose, torch.Tensor):
            if hand_pose.dim() == 2:
                num_grasps, pose_dim = hand_pose.shape
                logger.info(f"  âœ… å¤šæŠ“å–æ•°æ®æ ¼å¼æ­£ç¡®: ({num_grasps}, {pose_dim})")
                logger.info(f"     - æŠ“å–æ•°é‡: {num_grasps}")
                logger.info(f"     - å§¿æ€ç»´åº¦: {pose_dim}")
            else:
                logger.warning(f"  âš ï¸ æ‰‹éƒ¨å§¿æ€æ•°æ®ç»´åº¦å¼‚å¸¸: {hand_pose.shape}")
        else:
            logger.warning("  âš ï¸ æ‰‹éƒ¨å§¿æ€æ•°æ®ç±»å‹å¼‚å¸¸")
    
    # æ£€æŸ¥SE3çŸ©é˜µ
    if 'se3' in sample:
        se3_matrices = sample['se3']
        if isinstance(se3_matrices, torch.Tensor):
            if se3_matrices.dim() == 3 and se3_matrices.shape[1:] == (4, 4):
                num_se3 = se3_matrices.shape[0]
                logger.info(f"  âœ… SE3çŸ©é˜µæ ¼å¼æ­£ç¡®: ({num_se3}, 4, 4)")
            else:
                logger.warning(f"  âš ï¸ SE3çŸ©é˜µæ ¼å¼å¼‚å¸¸: {se3_matrices.shape}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æˆåŠŸæŠ“å–æ•°æ®
    if 'hand_model_pose' in sample:
        hand_pose = sample['hand_model_pose']
        if isinstance(hand_pose, torch.Tensor) and hand_pose.numel() > 0:
            logger.info("  âœ… æˆåŠŸåŠ è½½æ‰‹éƒ¨å§¿æ€æ•°æ® (succ_grasp_dir å‚æ•°å·¥ä½œæ­£å¸¸)")
        else:
            logger.warning("  âš ï¸ æ‰‹éƒ¨å§¿æ€æ•°æ®ä¸ºç©º")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ç‰©ä½“ç½‘æ ¼æ•°æ®
    if 'obj_verts' in sample and 'obj_faces' in sample:
        obj_verts = sample['obj_verts']
        obj_faces = sample['obj_faces']
        if isinstance(obj_verts, torch.Tensor) and obj_verts.numel() > 0:
            logger.info("  âœ… æˆåŠŸåŠ è½½ç‰©ä½“ç½‘æ ¼æ•°æ® (obj_root_dir å‚æ•°å·¥ä½œæ­£å¸¸)")
        else:
            logger.warning("  âš ï¸ ç‰©ä½“ç½‘æ ¼æ•°æ®ä¸ºç©º")
    
    # æ£€æŸ¥ç‚¹äº‘æ•°æ®
    if 'scene_pc' in sample:
        scene_pc = sample['scene_pc']
        if isinstance(scene_pc, torch.Tensor) and scene_pc.shape[1] == 6:
            logger.info("  âœ… 6Dç‚¹äº‘æ•°æ®æ ¼å¼æ­£ç¡® (xyz+rgb)")
        else:
            logger.warning(f"  âš ï¸ ç‚¹äº‘æ•°æ®æ ¼å¼å¼‚å¸¸: {scene_pc.shape if hasattr(scene_pc, 'shape') else type(scene_pc)}")
    
    return sample

def create_coordinate_frame(size: float = 0.1) -> o3d.geometry.TriangleMesh:
    """åˆ›å»ºåæ ‡è½´å‚è€ƒæ¡†æ¶"""
    return o3d.geometry.TriangleMesh.create_coordinate_frame(size=size)

def create_point_cloud_from_sample(scene_pc: torch.Tensor) -> o3d.geometry.PointCloud:
    """ä»æ ·æœ¬æ•°æ®åˆ›å»ºOpen3Dç‚¹äº‘"""
    if isinstance(scene_pc, torch.Tensor):
        scene_pc_np = scene_pc.detach().cpu().numpy()
    else:
        scene_pc_np = scene_pc
    
    # ç¡®ä¿å½¢çŠ¶æ­£ç¡®
    if len(scene_pc_np.shape) != 2 or scene_pc_np.shape[1] != 6:
        logger.warning(f"ç‚¹äº‘æ•°æ®å½¢çŠ¶å¼‚å¸¸: {scene_pc_np.shape}")
        return o3d.geometry.PointCloud()
    
    # æå–xyzåæ ‡å’Œrgbé¢œè‰²
    xyz = scene_pc_np[:, :3]
    rgb = scene_pc_np[:, 3:6]
    
    # åˆ›å»ºOpen3Dç‚¹äº‘
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(xyz)
    pcd.colors = o3d.utility.Vector3dVector(rgb)
    
    return pcd

def create_object_mesh(obj_verts: torch.Tensor, obj_faces: torch.Tensor,
                      color: Tuple[float, float, float] = (0.0, 1.0, 0.0)) -> Optional[o3d.geometry.TriangleMesh]:
    """ä»é¡¶ç‚¹å’Œé¢æ•°æ®åˆ›å»ºç›®æ ‡ç‰©ä½“mesh"""
    try:
        if obj_verts.numel() == 0 or obj_faces.numel() == 0:
            return None
        
        vertices_np = obj_verts.detach().cpu().numpy()
        faces_np = obj_faces.detach().cpu().numpy()
        
        if vertices_np.shape[1] != 3 or faces_np.shape[1] != 3:
            return None
        
        object_mesh = o3d.geometry.TriangleMesh()
        object_mesh.vertices = o3d.utility.Vector3dVector(vertices_np)
        object_mesh.triangles = o3d.utility.Vector3iVector(faces_np.astype(np.int32))
        object_mesh.paint_uniform_color(color)
        object_mesh.compute_vertex_normals()
        
        return object_mesh
    except Exception as e:
        logger.error(f"åˆ›å»ºç‰©ä½“meshå¤±è´¥: {e}")
        return None

def create_hand_meshes(hand_poses: torch.Tensor, hand_model: HandModel,
                      grasp_indices: Optional[List[int]] = None) -> List[o3d.geometry.TriangleMesh]:
    """
    ä»å¤šä¸ªæ‰‹éƒ¨å§¿æ€åˆ›å»ºæ‰‹éƒ¨meshåˆ—è¡¨
    ä½¿ç”¨æ–°çš„ utils/hand_model.pyï¼Œæ”¯æŒæ‰¹é‡è¾“å…¥æ ¼å¼ (B, num_grasps, pose_dim)

    Args:
        hand_poses: torch.Tensor of shape (num_grasps, 23) - å¤šä¸ªæ‰‹éƒ¨å§¿æ€å‚æ•°
        hand_model: HandModel - æ‰‹éƒ¨æ¨¡å‹å®ä¾‹
        grasp_indices: Optional[List[int]] - è¦å¯è§†åŒ–çš„æŠ“å–ç´¢å¼•ï¼ŒNoneè¡¨ç¤ºæ˜¾ç¤ºæ‰€æœ‰æŠ“å–

    Returns:
        List[o3d.geometry.TriangleMesh]: æ‰‹éƒ¨meshåˆ—è¡¨
    """
    hand_meshes = []

    if hand_poses.dim() == 1:
        hand_poses = hand_poses.unsqueeze(0)

    num_grasps = hand_poses.shape[0]

    # ç¡®å®šè¦æ˜¾ç¤ºçš„æŠ“å–ç´¢å¼•
    indices_to_show = []
    if grasp_indices is not None:
        indices_to_show = [i for i in grasp_indices if 0 <= i < num_grasps]
    else:
        # é»˜è®¤æ˜¾ç¤ºæ‰€æœ‰æŠ“å–
        indices_to_show = list(range(num_grasps))

    logger.info(f"å‡†å¤‡å¯è§†åŒ–æŠ“å–ç´¢å¼•: {indices_to_show}")
    
    if not indices_to_show:
        return []

    selected_poses = hand_poses[indices_to_show]

    # å…³é”®æ­¥éª¤ï¼šè¿‡æ»¤æ‰æ— æ•ˆçš„ï¼ˆé›¶å¡«å……çš„ï¼‰æŠ“å–å§¿æ€
    valid_mask = selected_poses.abs().sum(dim=-1) > 1e-6
    valid_poses = selected_poses[valid_mask]
    
    # è·å–é€šè¿‡è¿‡æ»¤çš„åŸå§‹ç´¢å¼•ï¼Œç”¨äºæ—¥å¿—è®°å½•
    original_indices_of_valid_poses = [indices_to_show[i] for i, is_valid in enumerate(valid_mask) if is_valid]

    if valid_poses.shape[0] < len(indices_to_show):
        logger.info(f"è¿‡æ»¤æ‰ {len(indices_to_show) - valid_poses.shape[0]} ä¸ªæ— æ•ˆçš„ (é›¶å¡«å……) æŠ“å–ã€‚")

    if valid_poses.shape[0] == 0:
        logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æŠ“å–å§¿æ€å¯ä¾›å¯è§†åŒ–ã€‚")
        return []

    logger.info(f"æ­£åœ¨ä¸º {len(valid_poses)} ä¸ªæœ‰æ•ˆæŠ“å–åˆ›å»ºmesh...")

    try:
        # ä¸ºæ¯ä¸ªæœ‰æ•ˆçš„æŠ“å–å•ç‹¬è®¾ç½®å‚æ•°å¹¶åˆ›å»ºmesh
        for i, single_pose in enumerate(valid_poses):
            original_grasp_idx = original_indices_of_valid_poses[i]
            try:
                hand_model.set_parameters(single_pose)
                trimesh_data = hand_model.get_trimesh_data(0)

                hand_mesh = o3d.geometry.TriangleMesh()
                hand_mesh.vertices = o3d.utility.Vector3dVector(trimesh_data.vertices)
                hand_mesh.triangles = o3d.utility.Vector3iVector(trimesh_data.faces)

                colors = [
                    [0.0, 0.0, 1.0],  # è“è‰²
                    [1.0, 0.0, 1.0],  # ç´«è‰²
                    [0.0, 1.0, 1.0],  # é’è‰²
                    [1.0, 0.5, 0.0],  # æ©™è‰²
                    [0.5, 0.0, 1.0],  # ç´«è“è‰²
                    [1.0, 1.0, 0.0],  # é»„è‰²
                    [0.0, 0.5, 1.0],  # æµ…è“è‰²
                    [1.0, 0.0, 0.5],  # ç²‰çº¢è‰²
                ]
                color = colors[i % len(colors)]
                hand_mesh.paint_uniform_color(color)
                hand_mesh.compute_vertex_normals()

                hand_meshes.append(hand_mesh)
                logger.info(f"âœ… æŠ“å– {original_grasp_idx} çš„æ‰‹éƒ¨meshåˆ›å»ºæˆåŠŸ (é¢œè‰²: {color})")

            except Exception as e:
                logger.error(f"åˆ›å»ºæŠ“å– {original_grasp_idx} çš„æ‰‹éƒ¨meshå¤±è´¥: {e}")
                continue

    except Exception as e:
        logger.error(f"è®¾ç½®æ‰‹éƒ¨å‚æ•°æˆ–åˆ›å»ºmeshæ—¶å‡ºé”™: {e}")
        return []

    return hand_meshes

def visualize_cached_sample(dataset, sample_idx: int = 0, grasp_indices: Optional[List[int]] = None):
    """å¯è§†åŒ–ç¼“å­˜æ•°æ®é›†æ ·æœ¬"""
    logger.info(f"=" * 60)
    logger.info(f"å¯è§†åŒ–ç¼“å­˜æ•°æ®é›†æ ·æœ¬ {sample_idx}")
    logger.info(f"=" * 60)

    try:
        # è·å–æ ·æœ¬æ•°æ®
        start_time = time.time()
        sample = dataset[sample_idx]
        load_time = time.time() - start_time
        logger.info(f"æ ·æœ¬åŠ è½½æ—¶é—´: {load_time:.4f} ç§’")

        # åˆ†ææ ·æœ¬æ•°æ®
        sample = analyze_sample_data(sample, sample_idx)

        # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
        if 'error' in sample:
            logger.error(f"æ ·æœ¬åŒ…å«é”™è¯¯: {sample['error']}")
            return

        # åˆ›å»ºå¯è§†åŒ–å¯¹è±¡åˆ—è¡¨
        vis_objects = []

        # æ·»åŠ åæ ‡è½´
        coordinate_frame = create_coordinate_frame(size=0.1)
        vis_objects.append(coordinate_frame)

        # åˆ›å»ºç‚¹äº‘
        if 'scene_pc' in sample:
            scene_pc = sample['scene_pc']
            pcd = create_point_cloud_from_sample(scene_pc)
            if len(pcd.points) > 0:
                vis_objects.append(pcd)
                logger.info(f"âœ… ç‚¹äº‘åˆ›å»ºæˆåŠŸ: {len(pcd.points)} ä¸ªç‚¹")

        # åˆ›å»ºç›®æ ‡ç‰©ä½“mesh
        if 'obj_verts' in sample and 'obj_faces' in sample:
            obj_verts = sample['obj_verts']
            obj_faces = sample['obj_faces']
            object_mesh = create_object_mesh(obj_verts, obj_faces, color=(0.0, 0.8, 0.0))
            if object_mesh is not None:
                vis_objects.append(object_mesh)
                logger.info(f"âœ… ç‰©ä½“meshåˆ›å»ºæˆåŠŸ")

        # åˆ›å»ºå¤šä¸ªæ‰‹éƒ¨æ¨¡å‹
        if 'hand_model_pose' in sample:
            try:
                hand_model = HandModel(hand_model_type=HandModelType.LEAP, device='cpu')
                hand_poses = sample['hand_model_pose']

                # ç¡®å®šè¦æ˜¾ç¤ºçš„æŠ“å–æ•°é‡
                if hand_poses.dim() == 2:
                    num_grasps = hand_poses.shape[0]
                    logger.info(f"æ ·æœ¬åŒ…å« {num_grasps} ä¸ªæŠ“å–å§¿æ€")

                    # ç¡®å®šè¦æ˜¾ç¤ºçš„æŠ“å–ç´¢å¼•
                    if grasp_indices is None:
                        grasp_indices = list(range(num_grasps))
                        logger.info(f"æ˜¾ç¤ºæ‰€æœ‰ {num_grasps} ä¸ªæŠ“å–")
                    else:
                        logger.info(f"æ˜¾ç¤ºæŒ‡å®šçš„æŠ“å–: {grasp_indices}")

                    hand_meshes = create_hand_meshes(hand_poses, hand_model, grasp_indices)
                else:
                    # å•ä¸ªæŠ“å–çš„æƒ…å†µ
                    logger.info("æ ·æœ¬åŒ…å«å•ä¸ªæŠ“å–å§¿æ€")
                    hand_meshes = create_hand_meshes(hand_poses, hand_model, [0])

                if hand_meshes:
                    vis_objects.extend(hand_meshes)
                    logger.info(f"âœ… {len(hand_meshes)} ä¸ªæ‰‹éƒ¨meshåˆ›å»ºæˆåŠŸ")
                else:
                    logger.warning("âœ— æ‰‹éƒ¨meshåˆ›å»ºå¤±è´¥")

            except Exception as e:
                logger.warning(f"æ‰‹éƒ¨æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")

        # æ˜¾ç¤ºå¯è§†åŒ–
        window_name = f"SceneLeapPlusDatasetCached - Sample {sample_idx}"
        if 'obj_code' in sample:
            window_name += f" - {sample['obj_code']}"
        if 'hand_model_pose' in sample and sample['hand_model_pose'].dim() == 2:
            num_grasps = sample['hand_model_pose'].shape[0]
            num_shown = len(grasp_indices) if grasp_indices else num_grasps
            window_name += f" ({num_shown}/{num_grasps} grasps)"

        logger.info(f"å¯åŠ¨å¯è§†åŒ–çª—å£...")
        logger.info("å¯è§†åŒ–è¯´æ˜:")
        logger.info("  - RGBåæ ‡è½´: ä¸–ç•Œåæ ‡ç³»")
        logger.info("  - å½©è‰²ç‚¹äº‘: åœºæ™¯ç‚¹äº‘ (xyz+rgb)")
        logger.info("  - ç»¿è‰²mesh: ç›®æ ‡ç‰©ä½“")
        logger.info("  - å½©è‰²mesh: å¤šä¸ªæ‰‹éƒ¨æ¨¡å‹")
        logger.info("    * è“è‰²: æŠ“å–1, ç´«è‰²: æŠ“å–2, é’è‰²: æŠ“å–3, æ©™è‰²: æŠ“å–4...")

        o3d.visualization.draw_geometries(
            vis_objects,
            window_name=window_name,
            width=1200,
            height=800,
            left=50,
            top=50
        )

    except Exception as e:
        logger.error(f"å¯è§†åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def test_different_modes():
    """æµ‹è¯•ä¸åŒçš„åæ ‡ç³»ç»Ÿæ¨¡å¼"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•ä¸åŒåæ ‡ç³»ç»Ÿæ¨¡å¼çš„ç¼“å­˜æ•°æ®é›†")
    logger.info("=" * 60)

    # æ”¯æŒçš„å››ç§æ¨¡å¼
    modes = ["camera_centric", "object_centric", "camera_centric_obj_mean_normalized", "camera_centric_scene_mean_normalized"]

    datasets = {}

    for mode in modes:
        try:
            logger.info(f"åˆ›å»º {mode} æ¨¡å¼çš„ç¼“å­˜æ•°æ®é›†...")
            start_time = time.time()

            dataset = SceneLeapPlusDatasetCached(
                root_dir=ROOT_DIR,
                succ_grasp_dir=SUCC_GRASP_DIR,
                obj_root_dir=OBJ_ROOT_DIR,
                num_grasps=4,  # SceneLeapPlusç‰¹æœ‰å‚æ•°
                mode=mode,
                max_grasps_per_object=2,
                mesh_scale=0.1,
                num_neg_prompts=4,
                enable_cropping=True,
                max_points=5000,  # å‡å°‘ç‚¹äº‘å¤§å°ä»¥åŠ å¿«æµ‹è¯•
                grasp_sampling_strategy="random",
                cache_version=f"v2.0_plus_test_{mode}",  # æ›´æ–°ç¼“å­˜ç‰ˆæœ¬
                # ç©·å°½é‡‡æ ·å‚æ•°
                use_exhaustive_sampling=False,  # å¯ä»¥è®¾ä¸ºTrueæµ‹è¯•ç©·å°½é‡‡æ ·
                exhaustive_sampling_strategy="sequential"
            )

            creation_time = time.time() - start_time
            datasets[mode] = dataset

            logger.info(f"âœ… {mode} æ¨¡å¼åˆ›å»ºæˆåŠŸ")
            logger.info(f"   - æ•°æ®é‡: {len(dataset)}")
            logger.info(f"   - åˆ›å»ºæ—¶é—´: {creation_time:.2f} ç§’")
            logger.info(f"   - æ¯ä¸ªæ ·æœ¬æŠ“å–æ•°é‡: {dataset.num_grasps}")

            # åˆ†æç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç‚¹äº‘ç»Ÿè®¡ä¿¡æ¯
            if len(dataset) > 0:
                sample = dataset[0]
                if 'scene_pc' in sample:
                    scene_pc = sample['scene_pc']
                    if isinstance(scene_pc, torch.Tensor) and scene_pc.numel() > 0:
                        xyz = scene_pc[:, :3]
                        mean_xyz = torch.mean(xyz, dim=0)
                        std_xyz = torch.std(xyz, dim=0)
                        min_xyz = torch.min(xyz, dim=0)[0]
                        max_xyz = torch.max(xyz, dim=0)[0]

                        logger.info(f"   - ç‚¹äº‘ç»Ÿè®¡ (xyz):")
                        logger.info(f"     å‡å€¼: [{mean_xyz[0]:.3f}, {mean_xyz[1]:.3f}, {mean_xyz[2]:.3f}]")
                        logger.info(f"     æ ‡å‡†å·®: [{std_xyz[0]:.3f}, {std_xyz[1]:.3f}, {std_xyz[2]:.3f}]")
                        logger.info(f"     èŒƒå›´: [{min_xyz[0]:.3f}, {max_xyz[0]:.3f}]")

        except Exception as e:
            logger.error(f"âŒ {mode} æ¨¡å¼åˆ›å»ºå¤±è´¥: {e}")
            continue

    # æä¾›äº¤äº’å¼é€‰æ‹©å¯è§†åŒ–
    if datasets:
        logger.info(f"\næˆåŠŸåˆ›å»ºäº† {len(datasets)} ä¸ªæ¨¡å¼çš„æ•°æ®é›†")
        logger.info("å¯ç”¨æ¨¡å¼:")
        for i, mode in enumerate(datasets.keys(), 1):
            logger.info(f"  {i}. {mode}")

        try:
            choice = input("\nè¯·é€‰æ‹©è¦å¯è§†åŒ–çš„æ¨¡å¼ (è¾“å…¥æ•°å­—) æˆ–æŒ‰å›è½¦è·³è¿‡: ").strip()
            if choice.isdigit():
                mode_idx = int(choice) - 1
                mode_list = list(datasets.keys())
                if 0 <= mode_idx < len(mode_list):
                    selected_mode = mode_list[mode_idx]
                    logger.info(f"å¯è§†åŒ– {selected_mode} æ¨¡å¼...")
                    visualize_cached_sample(datasets[selected_mode], 0)
        except Exception as e:
            logger.warning(f"å¯è§†åŒ–é€‰æ‹©å¤±è´¥: {e}")

    return datasets

def test_data_consistency():
    """æµ‹è¯•æ•°æ®ä¸€è‡´æ€§"""
    logger.info("=" * 60)
    logger.info("æµ‹è¯•åŸå§‹æ•°æ®é›†ä¸ç¼“å­˜æ•°æ®é›†çš„ä¸€è‡´æ€§")
    logger.info("=" * 60)

    try:
        # åˆ›å»ºåŸå§‹æ•°æ®é›†ï¼ˆå°è§„æ¨¡ï¼‰
        logger.info("åˆ›å»ºåŸå§‹æ•°æ®é›†...")
        original_dataset = SceneLeapPlusDataset(
            root_dir=ROOT_DIR,
            succ_grasp_dir=SUCC_GRASP_DIR,
            obj_root_dir=OBJ_ROOT_DIR,
            num_grasps=4,
            mode="camera_centric",
            max_grasps_per_object=2,
            mesh_scale=0.1,
            num_neg_prompts=4,
            enable_cropping=True,
            max_points=10000,
            grasp_sampling_strategy="random",
            # ç©·å°½é‡‡æ ·å‚æ•°
            use_exhaustive_sampling=False,
            exhaustive_sampling_strategy="sequential"
        )

        # åˆ›å»ºç¼“å­˜æ•°æ®é›†
        logger.info("åˆ›å»ºç¼“å­˜æ•°æ®é›†...")
        cached_dataset = SceneLeapPlusDatasetCached(
            root_dir=ROOT_DIR,
            succ_grasp_dir=SUCC_GRASP_DIR,
            obj_root_dir=OBJ_ROOT_DIR,
            num_grasps=4,
            mode="camera_centric_scene_mean_normalized",
            max_grasps_per_object=2,  # é™åˆ¶æ•°æ®é‡
            mesh_scale=0.1,
            num_neg_prompts=4,
            enable_cropping=True,
            max_points=10000,  # é™åˆ¶ç‚¹äº‘å¤§å°
            grasp_sampling_strategy="random",
            cache_version="v2.0_plus_consistency_test",  # æ›´æ–°ç¼“å­˜ç‰ˆæœ¬
            # ç©·å°½é‡‡æ ·å‚æ•°
            use_exhaustive_sampling=False,
            exhaustive_sampling_strategy="sequential"
        )

        # æ¯”è¾ƒæ•°æ®é‡
        logger.info(f"åŸå§‹æ•°æ®é›†å¤§å°: {len(original_dataset)}")
        logger.info(f"ç¼“å­˜æ•°æ®é›†å¤§å°: {len(cached_dataset)}")

        if len(original_dataset) == len(cached_dataset):
            logger.info("âœ… æ•°æ®é‡ä¸€è‡´")
        else:
            logger.warning("âš ï¸ æ•°æ®é‡ä¸ä¸€è‡´")

        # æ¯”è¾ƒç¬¬ä¸€ä¸ªæ ·æœ¬çš„å…³é”®å­—æ®µ
        if len(cached_dataset) > 0:
            logger.info("æ¯”è¾ƒç¬¬ä¸€ä¸ªæ ·æœ¬...")
            original_sample = original_dataset[0]
            cached_sample = cached_dataset[0]

            # æ¯”è¾ƒå…³é”®å­—æ®µ
            key_fields = ['scene_pc', 'hand_model_pose', 'positive_prompt']
            for field in key_fields:
                if field in original_sample and field in cached_sample:
                    if isinstance(original_sample[field], torch.Tensor):
                        # å¯¹äºå¤šæŠ“å–æ•°æ®ï¼Œæ¯”è¾ƒå½¢çŠ¶
                        if original_sample[field].shape == cached_sample[field].shape:
                            logger.info(f"  âœ… {field} å½¢çŠ¶ä¸€è‡´: {original_sample[field].shape}")
                        else:
                            logger.warning(f"  âš ï¸ {field} å½¢çŠ¶ä¸ä¸€è‡´: {original_sample[field].shape} vs {cached_sample[field].shape}")
                    else:
                        if original_sample[field] == cached_sample[field]:
                            logger.info(f"  âœ… {field} æ•°æ®ä¸€è‡´")
                        else:
                            logger.warning(f"  âš ï¸ {field} æ•°æ®ä¸ä¸€è‡´")

        return True

    except Exception as e:
        logger.error(f"ä¸€è‡´æ€§æµ‹è¯•å¤±è´¥: {e}")
        return False

def interactive_visualization(dataset):
    """äº¤äº’å¼å¯è§†åŒ–ï¼Œå…è®¸æµè§ˆä¸åŒæ ·æœ¬"""
    logger.info("=" * 60)
    logger.info("äº¤äº’å¼å¯è§†åŒ–æ¨¡å¼")
    logger.info("=" * 60)

    if len(dataset) == 0:
        logger.error("æ•°æ®é›†ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå¯è§†åŒ–")
        return

    logger.info(f"æ•°æ®é›†åŒ…å« {len(dataset)} ä¸ªæ ·æœ¬")
    logger.info("è¾“å…¥æ ·æœ¬ç´¢å¼•è¿›è¡Œå¯è§†åŒ–ï¼Œè¾“å…¥ 'q' é€€å‡º")
    logger.info("å¯ä»¥æŒ‡å®šè¦æ˜¾ç¤ºçš„æŠ“å–ç´¢å¼•ï¼Œä¾‹å¦‚: '0 [0,1,2]' æ˜¾ç¤ºæ ·æœ¬0çš„å‰3ä¸ªæŠ“å–")

    while True:
        try:
            user_input = input(f"\nè¯·è¾“å…¥æ ·æœ¬ç´¢å¼• (0-{len(dataset)-1}) [å¯é€‰:æŠ“å–ç´¢å¼•åˆ—è¡¨] æˆ– 'q' é€€å‡º: ").strip()

            if user_input.lower() == 'q':
                logger.info("é€€å‡ºäº¤äº’å¼å¯è§†åŒ–")
                break

            # è§£æè¾“å…¥
            parts = user_input.split()
            sample_idx = int(parts[0])

            grasp_indices = None
            if len(parts) > 1:
                # è§£ææŠ“å–ç´¢å¼•åˆ—è¡¨ï¼Œä¾‹å¦‚ [0,1,2]
                grasp_str = parts[1].strip('[]')
                if grasp_str:
                    grasp_indices = [int(x.strip()) for x in grasp_str.split(',')]

            if 0 <= sample_idx < len(dataset):
                if grasp_indices:
                    logger.info(f"å¯è§†åŒ–æ ·æœ¬ {sample_idx}ï¼ŒæŠ“å–ç´¢å¼•: {grasp_indices}")
                    visualize_cached_sample(dataset, sample_idx, grasp_indices=grasp_indices)
                else:
                    logger.info(f"å¯è§†åŒ–æ ·æœ¬ {sample_idx}ï¼Œæ˜¾ç¤ºæ‰€æœ‰æŠ“å–")
                    visualize_cached_sample(dataset, sample_idx)
            else:
                logger.warning(f"ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œè¯·è¾“å…¥ 0-{len(dataset)-1} ä¹‹é—´çš„æ•°å­—")

        except ValueError:
            logger.warning("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—æˆ– 'q'")
        except KeyboardInterrupt:
            logger.info("\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºäº¤äº’å¼å¯è§†åŒ–")
            break
        except Exception as e:
            logger.error(f"å¯è§†åŒ–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("SceneLeapPlusDatasetCached å¯è§†åŒ–æµ‹è¯•è„šæœ¬")
    logger.info("éªŒè¯ä¿®å¤åçš„ç¼“å­˜æ•°æ®é›†ç±»åŠŸèƒ½")
    logger.info("=" * 80)

    # éªŒè¯è·¯å¾„
    if not verify_paths():
        logger.error("æ•°æ®è·¯å¾„éªŒè¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥è·¯å¾„è®¾ç½®")
        return

    # æµ‹è¯•é€‰é¡¹
    tests = [
        ("1", "åˆ›å»ºå’Œæµ‹è¯• SceneLeapPlusDatasetCached", test_cached_dataset_creation),
        ("2", "æµ‹è¯•ä¸åŒåæ ‡ç³»ç»Ÿæ¨¡å¼", test_different_modes),
        ("3", "æ•°æ®ä¸€è‡´æ€§æµ‹è¯•", test_data_consistency),
        ("4", "äº¤äº’å¼å¯è§†åŒ–", None),  # ç‰¹æ®Šå¤„ç†
        ("5", "è¿è¡Œæ‰€æœ‰æµ‹è¯•", None),  # ç‰¹æ®Šå¤„ç†
    ]

    logger.info("å¯ç”¨æµ‹è¯•é€‰é¡¹:")
    for option, description, _ in tests:
        logger.info(f"  {option}. {description}")

    while True:
        try:
            choice = input("\nè¯·é€‰æ‹©æµ‹è¯•é€‰é¡¹ (1-5) æˆ– 'q' é€€å‡º: ").strip()

            if choice.lower() == 'q':
                logger.info("é€€å‡ºæµ‹è¯•")
                break

            if choice == "1":
                dataset = test_cached_dataset_creation()
                if dataset is not None:
                    # å¯è§†åŒ–ç¬¬ä¸€ä¸ªæ ·æœ¬
                    if len(dataset) > 0:
                        visualize_cached_sample(dataset, 0)
                    else:
                        logger.warning("æ•°æ®é›†ä¸ºç©º")

            elif choice == "2":
                test_different_modes()

            elif choice == "3":
                test_data_consistency()

            elif choice == "4":
                # äº¤äº’å¼å¯è§†åŒ–
                logger.info("åˆ›å»ºæ•°æ®é›†ç”¨äºäº¤äº’å¼å¯è§†åŒ–...")
                dataset = test_cached_dataset_creation()
                if dataset is not None:
                    interactive_visualization(dataset)

            elif choice == "5":
                # è¿è¡Œæ‰€æœ‰æµ‹è¯•
                logger.info("è¿è¡Œæ‰€æœ‰æµ‹è¯•...")

                # æµ‹è¯•1: SceneLeapPlusDatasetCached
                dataset1 = test_cached_dataset_creation()

                # æµ‹è¯•2: ä¸åŒæ¨¡å¼æµ‹è¯•
                test_different_modes()

                # æµ‹è¯•3: æ•°æ®ä¸€è‡´æ€§
                test_data_consistency()

                # å¯è§†åŒ–ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ•°æ®é›†
                if dataset1 is not None and len(dataset1) > 0:
                    logger.info("å¯è§†åŒ– SceneLeapPlusDatasetCached ç¬¬ä¸€ä¸ªæ ·æœ¬...")
                    visualize_cached_sample(dataset1, 0)

                logger.info("æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
                logger.info("\nSceneLeapPlusDatasetCachedç‰¹æ€§æ€»ç»“:")
                logger.info(f"  - æ¯ä¸ªæ ·æœ¬åŒ…å«å›ºå®šæ•°é‡çš„æŠ“å–å§¿æ€")
                logger.info(f"  - æ”¯æŒå¤šæŠ“å–å¹¶è¡Œå­¦ä¹ æ¶æ„")
                logger.info(f"  - HDF5ç¼“å­˜å­˜å‚¨ï¼Œæé«˜æ•°æ®åŠ è½½æ•ˆç‡")
                logger.info(f"  - æ‰‹éƒ¨å§¿æ€å½¢çŠ¶: (num_grasps, 23)")
                logger.info(f"  - SE3çŸ©é˜µå½¢çŠ¶: (num_grasps, 4, 4)")
                logger.info(f"  - ä¸åŒæŠ“å–ä½¿ç”¨ä¸åŒé¢œè‰²åŒºåˆ†")
                logger.info(f"  - ğŸ†• æ”¯æŒç©·å°½é‡‡æ ·ï¼šå®ç°100%æ•°æ®åˆ©ç”¨ç‡")
                logger.info(f"  - ğŸ†• æ”¯æŒ5ç§ç©·å°½é‡‡æ ·ç­–ç•¥ï¼šsequential, random, interleaved, chunk_farthest_point, chunk_nearest_point")
                logger.info(f"  - ğŸ†• ä¿®å¤ç¼“å­˜æ–‡ä»¶åç”Ÿæˆï¼ŒåŒ…å«æ‰€æœ‰å…³é”®å‚æ•°")
                logger.info(f"  - ğŸ†• æ•°æ®é›†å¯æ‰©å±•10-50å€ï¼Œå¤§å¹…æå‡è®­ç»ƒæ•ˆç‡")

            else:
                logger.warning("æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-5 æˆ– 'q'")

        except KeyboardInterrupt:
            logger.info("\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºæµ‹è¯•")
            break
        except Exception as e:
            logger.error(f"æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main()
