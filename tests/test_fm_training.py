"""
Flow Matching è®­ç»ƒå¾ªç¯æµ‹è¯•

æµ‹è¯•FMè®­ç»ƒçš„å®Œæ•´æµç¨‹ï¼ŒéªŒè¯1ä¸ªepochæ— NaN/Inf
"""

import torch
import sys
import os
sys.path.insert(0, '/home/xiantuo/source/grasp/GithubClone/SceneLeapUltra')

def test_fm_training_loop():
    """
    æµ‹è¯•FMè®­ç»ƒå¾ªç¯åŸºæœ¬åŠŸèƒ½
    
    è¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„è®­ç»ƒæµ‹è¯•ï¼Œä½¿ç”¨åˆæˆæ•°æ®éªŒè¯ï¼š
    1. æ•°æ®é¢„å¤„ç†
    2. æ—¶é—´é‡‡æ ·
    3. è·¯å¾„æ’å€¼
    4. æ¨¡å‹å‰å‘
    5. æŸå¤±è®¡ç®—
    6. åå‘ä¼ æ’­
    """
    print("="*60)
    print("Flow Matching è®­ç»ƒå¾ªç¯æµ‹è¯•")
    print("="*60)
    
    try:
        from omegaconf import OmegaConf
        from models.decoder.dit_fm import DiTFM
        from models.fm.paths import linear_ot_path
        from utils.hand_helper import process_hand_pose
        import torch.nn.functional as F
        
        # æ£€æŸ¥GPU
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
        
        if device == 'cpu':
            print("âš ï¸  CPUç¯å¢ƒï¼Œè·³è¿‡å®Œæ•´è®­ç»ƒæµ‹è¯•")
            print("   (PointNet2 backboneéœ€è¦GPU)")
            return True
        
        print("\né˜¶æ®µ1: æ¨¡å‹åˆå§‹åŒ–")
        # åˆ›å»ºé…ç½®
        cfg = OmegaConf.create({
            'name': 'dit_fm',
            'mode': 'velocity',
            'rot_type': 'r6d',
            'd_model': 256,
            'num_layers': 2,
            'num_heads': 4,
            'd_head': 64,
            'dropout': 0.0,
            'max_sequence_length': 100,
            'use_learnable_pos_embedding': False,
            'time_embed_dim': 512,
            'use_adaptive_norm': True,
            'continuous_time': True,
            'freq_dim': 128,
            'use_text_condition': False,
            'text_dropout_prob': 0.1,
            'use_negative_prompts': False,
            'use_object_mask': False,
            'use_rgb': False,
            'backbone': OmegaConf.load('config/model/diffuser/decoder/backbone/pointnet2.yaml'),
            'debug': {
                'check_nan': True,
                'log_tensor_stats': False
            }
        })
        
        model = DiTFM(cfg).to(device)
        model.train()
        
        optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
        
        print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
        print(f"   å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")
        
        print("\né˜¶æ®µ2: åˆæˆè®­ç»ƒæ•°æ®")
        B, num_grasps, D = 2, 8, 25
        
        # æ¨¡æ‹Ÿbatchæ•°æ®
        batch = {
            'scene_pc': torch.randn(B, 4096, 3).to(device),
            'hand_model_pose': torch.randn(B, num_grasps, 23).to(device),
            'se3': torch.eye(4).unsqueeze(0).unsqueeze(0).expand(B, num_grasps, 4, 4).to(device),
        }
        
        print("âœ… åˆæˆæ•°æ®å‡†å¤‡å®Œæˆ")
        print(f"   Batch size: {B}, Grasps: {num_grasps}")
        
        print("\né˜¶æ®µ3: æ•°æ®é¢„å¤„ç†")
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œç›´æ¥åˆ›å»ºnorm_pose
        batch['norm_pose'] = torch.randn(B, num_grasps, D).to(device)
        
        x0 = batch['norm_pose']
        print("âœ… å½’ä¸€åŒ–å§¿æ€ç”Ÿæˆ")
        print(f"   norm_pose: {x0.shape}")
        
        print("\né˜¶æ®µ4: è®­ç»ƒæ­¥éª¤æ¨¡æ‹Ÿ")
        num_steps = 5
        losses = []
        
        for step in range(num_steps):
            optimizer.zero_grad()
            
            # é‡‡æ ·æ—¶é—´
            t = torch.rand(B).to(device)
            
            # é‡‡æ ·å™ªå£°
            x1 = torch.randn_like(x0)
            
            # Linear OTè·¯å¾„
            x_t, v_star = linear_ot_path(x0, x1, t)
            
            # é¢„è®¡ç®—æ¡ä»¶ï¼ˆæ¯æ­¥éƒ½é‡æ–°è®¡ç®—ä»¥é¿å…æ¢¯åº¦å›¾é—®é¢˜ï¼‰
            with torch.no_grad():
                condition_dict = model.condition(batch)
            batch_step = batch.copy()
            batch_step.update(condition_dict)
            
            # å‰å‘ä¼ æ’­
            v_pred = model(x_t, t, batch_step)
            
            # è®¡ç®—æŸå¤±
            loss = F.mse_loss(v_pred, v_star)
            
            # åå‘ä¼ æ’­
            loss.backward()
            
            # æ£€æŸ¥æ¢¯åº¦
            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
            
            # ä¼˜åŒ–å™¨æ­¥è¿›
            optimizer.step()
            
            losses.append(loss.item())
            
            # æ£€æŸ¥NaN/Inf
            if torch.isnan(loss):
                print(f"âŒ Step {step}: æŸå¤±ä¸ºNaN")
                return False
            if torch.isinf(loss):
                print(f"âŒ Step {step}: æŸå¤±ä¸ºInf")
                return False
            
            print(f"   Step {step+1}/{num_steps}: loss={loss.item():.4f}, "
                  f"grad_norm={grad_norm:.4f}, ||v_pred||={torch.norm(v_pred).item():.4f}")
        
        print("\nâœ… è®­ç»ƒå¾ªç¯æµ‹è¯•é€šè¿‡")
        print(f"   å¹³å‡æŸå¤±: {sum(losses)/len(losses):.4f}")
        print(f"   æŸå¤±èŒƒå›´: [{min(losses):.4f}, {max(losses):.4f}]")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_fm_sampling():
    """æµ‹è¯•FMé‡‡æ ·æµç¨‹"""
    print("\n" + "="*60)
    print("Flow Matching é‡‡æ ·æµ‹è¯•")
    print("="*60)
    
    try:
        from models.fm.solvers import rk4_solver, ODESolverStats
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
        
        if device == 'cpu':
            print("âš ï¸  CPUç¯å¢ƒï¼Œä½¿ç”¨ç®€åŒ–æµ‹è¯•")
        
        print("\né˜¶æ®µ1: å‡†å¤‡æ¨¡å‹å’Œæ•°æ®")
        B, num_grasps, D = 2, 8, 25
        
        # ç®€åŒ–çš„é€Ÿåº¦å‡½æ•°ï¼ˆä¸ä½¿ç”¨å®Œæ•´æ¨¡å‹ï¼‰
        def simple_velocity_fn(x, t, data):
            """ç®€å•çš„é€Ÿåº¦å‡½æ•°ç”¨äºæµ‹è¯•"""
            # çº¿æ€§OTçš„ç†è®ºé€Ÿåº¦ï¼šv = x1 - x0
            # è¿™é‡Œç”¨å¸¸æ•°è¿‘ä¼¼
            return torch.ones_like(x) * 0.5
        
        # åˆå§‹å™ªå£°
        x1 = torch.randn(B, num_grasps, D).to(device)
        data = {}
        
        print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ")
        
        print("\né˜¶æ®µ2: RK4é‡‡æ ·")
        stats = ODESolverStats()
        
        x0, info = rk4_solver(
            velocity_fn=simple_velocity_fn,
            x1=x1,
            data=data,
            nfe=32,
            reverse_time=True,
            save_trajectory=False,
            stats=stats
        )
        
        print("âœ… RK4é‡‡æ ·æˆåŠŸ")
        print(f"   NFE: {info['nfe']}")
        print(f"   æ¥å—æ­¥æ•°: {stats.accepted_steps}")
        print(f"   è¾“å…¥å½¢çŠ¶: {x1.shape}, è¾“å‡ºå½¢çŠ¶: {x0.shape}")
        print(f"   é‡‡æ ·æ—¶é—´: {stats.total_time:.4f}s")
        
        # éªŒè¯è¾“å‡º
        assert x0.shape == x1.shape, "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…"
        assert not torch.isnan(x0).any(), "è¾“å‡ºåŒ…å«NaN"
        assert not torch.isinf(x0).any(), "è¾“å‡ºåŒ…å«Inf"
        
        print("\nâœ… é‡‡æ ·æµ‹è¯•é€šè¿‡")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œè®­ç»ƒå’Œé‡‡æ ·æµ‹è¯•"""
    results = []
    
    # æµ‹è¯•1: è®­ç»ƒå¾ªç¯
    result1 = test_fm_training_loop()
    results.append(("è®­ç»ƒå¾ªç¯", result1))
    
    # æµ‹è¯•2: é‡‡æ ·æµç¨‹
    result2 = test_fm_sampling()
    results.append(("é‡‡æ ·æµç¨‹", result2))
    
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{status} - {name}")
    
    print(f"\né€šè¿‡ç‡: {passed}/{total} ({100*passed/total:.1f}%)")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼FMè®­ç»ƒå’Œé‡‡æ ·åŠŸèƒ½æ­£å¸¸ã€‚")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed}ä¸ªæµ‹è¯•å¤±è´¥ã€‚")
        return 1


if __name__ == "__main__":
    exit(main())

