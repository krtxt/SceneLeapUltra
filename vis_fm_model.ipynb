{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Flow Matching 模型可视化\n",
        "\n",
        "本notebook用于可视化Flow Matching模型的预测结果：\n",
        "1. 场景点云 + 预测抓取分布 + 目标抓取分布\n",
        "2. 匹配后的抓取3D模型 + 场景点云\n",
        "3. 使用ObjectCentric数据集（无RGB，无Object Mask）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"  # 设置使用的GPU\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from utils.color_utils import get_random_color\n",
        "from models.fm_lightning import FlowMatchingLightning\n",
        "from utils.hand_model import HandModel, HandModelType\n",
        "from datasets import build_datasets\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import random\n",
        "import trimesh\n",
        "from omegaconf import OmegaConf\n",
        "from utils.hand_helper import norm_hand_pose_robust, denorm_hand_pose_robust\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"✅ 导入完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. 配置和模型加载\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 设置路径和常量\n",
        "CKPT_PATH = 'experiments/fm_objcentric/checkpoints/epoch=479-val_loss=7.80.ckpt'  # FM checkpoint路径\n",
        "CONFIG_PATH = 'experiments/fm_objcentric/config/whole_config.yaml'\n",
        "DEVICE = 'cuda:0'\n",
        "BATCH_SIZE = 1  # 单个样本便于可视化\n",
        "NUM_GRASPS = 64\n",
        "\n",
        "print(f\"Checkpoint: {CKPT_PATH}\")\n",
        "print(f\"Config: {CONFIG_PATH}\")\n",
        "print(f\"Device: {DEVICE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载配置\n",
        "cfg = OmegaConf.load(CONFIG_PATH)\n",
        "cfg = OmegaConf.create(cfg)\n",
        "\n",
        "# 调整matcher的cost权重（可选）\n",
        "cfg.model.criterion.cost_weights.translation = 100.0\n",
        "cfg.model.criterion.cost_weights.rotation = 10.0\n",
        "\n",
        "print(\"配置信息:\")\n",
        "print(f\"  模型: {cfg.model.name}\")\n",
        "print(f\"  数据: {cfg.data_cfg.name}\")\n",
        "print(f\"  旋转类型: {cfg.model.rot_type}\")\n",
        "print(f\"  坐标系: {cfg.model.mode}\")\n",
        "print(f\"  预测模式: {cfg.model.decoder.pred_mode}\")\n",
        "print(f\"  求解器: {cfg.model.solver.type}, NFE={cfg.model.solver.nfe}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 创建Flow Matching模型\n",
        "model = FlowMatchingLightning(cfg.model)\n",
        "\n",
        "# 强制初始化text_encoder（如果使用文本条件）\n",
        "if hasattr(model.model, '_ensure_text_encoder') and cfg.model.decoder.use_text_condition:\n",
        "    print(\"正在初始化text_encoder...\")\n",
        "    model.model._ensure_text_encoder()\n",
        "    print(\"✅ text_encoder初始化完成\")\n",
        "\n",
        "# 加载checkpoint\n",
        "if os.path.exists(CKPT_PATH):\n",
        "    checkpoint = torch.load(CKPT_PATH, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['state_dict'], strict=True)\n",
        "    print(f\"✅ 模型加载成功 (strict=True)\")\n",
        "else:\n",
        "    print(f\"⚠️  Checkpoint不存在: {CKPT_PATH}\")\n",
        "    print(\"   将使用未训练的模型进行可视化\")\n",
        "\n",
        "# 移动到设备并设置为评估模式\n",
        "model.to(DEVICE).eval()\n",
        "print(f\"✅ 模型已移动到 {DEVICE} 并设置为评估模式\")\n",
        "\n",
        "# 创建hand model用于可视化\n",
        "hand_model = HandModel(\n",
        "    HandModelType.LEAP, \n",
        "    cfg.model.criterion.hand_model.n_surface_points, \n",
        "    cfg.model.criterion.rot_type, \n",
        "    DEVICE\n",
        ")\n",
        "print(f\"✅ Hand Model创建完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 数据加载\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 构建数据集（使用objectcentric配置）\n",
        "print(\"加载ObjectCentric数据集...\")\n",
        "train_dataset, val_dataset, test_dataset = build_datasets(cfg.data_cfg, stage='fit')\n",
        "\n",
        "print(f\"✅ 数据集加载完成\")\n",
        "print(f\"   训练集: {len(train_dataset)}\")\n",
        "print(f\"   验证集: {len(val_dataset)}\")\n",
        "\n",
        "# 创建dataloader\n",
        "val_loader = DataLoader(\n",
        "    val_dataset, \n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    collate_fn=val_dataset.collate_fn\n",
        ")\n",
        "\n",
        "print(f\"✅ DataLoader创建完成，batch_size={BATCH_SIZE}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 获取一个batch用于可视化\n",
        "batch = next(iter(val_loader))\n",
        "\n",
        "# 移动到device\n",
        "for key in batch:\n",
        "    if isinstance(batch[key], torch.Tensor):\n",
        "        batch[key] = batch[key].to(DEVICE)\n",
        "\n",
        "print(\"Batch信息:\")\n",
        "print(f\"  场景点云: {batch['scene_pc'].shape}\")\n",
        "print(f\"  手部姿态: {batch['hand_model_pose'].shape}\")\n",
        "print(f\"  SE3: {batch['se3'].shape}\")\n",
        "if 'positive_prompt' in batch:\n",
        "    print(f\"  物体名称: {batch['positive_prompt']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Flow Matching采样生成预测\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用Flow Matching进行采样\n",
        "print(\"开始Flow Matching采样...\")\n",
        "print(f\"  求解器: {cfg.model.solver.type}\")\n",
        "print(f\"  NFE: {cfg.model.solver.nfe}\")\n",
        "print(f\"  CFG: {cfg.model.guidance.enable_cfg}\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    # 使用sample方法进行ODE采样\n",
        "    pred_x0 = model.sample(batch, k=1)  # [B, num_grasps, D]\n",
        "\n",
        "print(f\"✅ 采样完成\")\n",
        "print(f\"   预测姿态: {pred_x0.shape}\")\n",
        "print(f\"   范围: [{pred_x0.min():.3f}, {pred_x0.max():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 反归一化得到实际手部姿态\n",
        "from utils.hand_helper import denorm_hand_pose_robust\n",
        "\n",
        "pred_hand_pose = denorm_hand_pose_robust(pred_x0, cfg.model.rot_type, cfg.model.mode)\n",
        "target_hand_pose = batch['hand_model_pose']\n",
        "\n",
        "print(\"手部姿态:\")\n",
        "print(f\"  预测: {pred_hand_pose.shape}\")\n",
        "print(f\"  目标: {target_hand_pose.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 生成手部表面点云\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 生成预测手部的表面点\n",
        "B, num_grasps, _ = pred_hand_pose.shape\n",
        "\n",
        "print(f\"生成 {B} x {num_grasps} = {B*num_grasps} 个手部模型...\")\n",
        "\n",
        "# 预测手部\n",
        "pred_hand_dict = hand_model(\n",
        "    pred_hand_pose.reshape(B * num_grasps, -1),\n",
        "    with_surface_points=True,\n",
        "    with_meshes=True\n",
        ")\n",
        "\n",
        "# Reshape回[B, num_grasps, ...]\n",
        "pred_surface_points = pred_hand_dict['surface_points'].reshape(B, num_grasps, -1, 3)\n",
        "pred_meshes = pred_hand_dict['meshes']  # List of meshes\n",
        "\n",
        "print(f\"✅ 预测手部表面点: {pred_surface_points.shape}\")\n",
        "\n",
        "# 目标手部\n",
        "target_hand_dict = hand_model(\n",
        "    target_hand_pose.reshape(B * num_grasps, -1),\n",
        "    with_surface_points=True,\n",
        "    with_meshes=True\n",
        ")\n",
        "\n",
        "target_surface_points = target_hand_dict['surface_points'].reshape(B, num_grasps, -1, 3)\n",
        "target_meshes = target_hand_dict['meshes']\n",
        "\n",
        "print(f\"✅ 目标手部表面点: {target_surface_points.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 可视化1：场景点云 + 预测抓取分布 + 目标抓取分布\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_grasps_distribution(scene_pc, pred_points, target_points, sample_idx=0, \n",
        "                                   num_grasps_to_show=64, title=\"Grasp Distribution\"):\n",
        "    \"\"\"\n",
        "    可视化场景点云和抓取分布\n",
        "    \n",
        "    Args:\n",
        "        scene_pc: 场景点云 [B, N, 3]\n",
        "        pred_points: 预测手部表面点 [B, num_grasps, N_hand, 3]\n",
        "        target_points: 目标手部表面点 [B, num_grasps, N_hand, 3]\n",
        "        sample_idx: 要可视化的样本索引\n",
        "        num_grasps_to_show: 显示的抓取数量\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # 1. 场景点云（灰色）\n",
        "    scene = scene_pc[sample_idx].cpu().numpy()\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=scene[:, 0],\n",
        "        y=scene[:, 1],\n",
        "        z=scene[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color='lightgray', opacity=0.3),\n",
        "        name='场景点云'\n",
        "    ))\n",
        "    \n",
        "    # 2. 预测抓取分布（蓝色）\n",
        "    for i in range(min(num_grasps_to_show, pred_points.shape[1])):\n",
        "        pred_hand = pred_points[sample_idx, i].cpu().numpy()\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=pred_hand[:, 0],\n",
        "            y=pred_hand[:, 1],\n",
        "            z=pred_hand[:, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(size=1, color='blue', opacity=0.4),\n",
        "            name=f'预测抓取{i}' if i < 3 else None,\n",
        "            showlegend=(i < 3),\n",
        "            legendgroup='pred'\n",
        "        ))\n",
        "    \n",
        "    # 3. 目标抓取分布（红色）\n",
        "    for i in range(min(num_grasps_to_show, target_points.shape[1])):\n",
        "        target_hand = target_points[sample_idx, i].cpu().numpy()\n",
        "        fig.add_trace(go.Scatter3d(\n",
        "            x=target_hand[:, 0],\n",
        "            y=target_hand[:, 1],\n",
        "            z=target_hand[:, 2],\n",
        "            mode='markers',\n",
        "            marker=dict(size=1, color='red', opacity=0.4),\n",
        "            name=f'目标抓取{i}' if i < 3 else None,\n",
        "            showlegend=(i < 3),\n",
        "            legendgroup='target'\n",
        "        ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        scene=dict(\n",
        "            xaxis=dict(title='X'),\n",
        "            yaxis=dict(title='Y'),\n",
        "            zaxis=dict(title='Z'),\n",
        "            aspectmode='data'\n",
        "        ),\n",
        "        width=1000,\n",
        "        height=800\n",
        "    )\n",
        "    \n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化抓取分布\n",
        "fig = visualize_grasps_distribution(\n",
        "    batch['scene_pc'],\n",
        "    pred_surface_points,\n",
        "    target_surface_points,\n",
        "    sample_idx=0,\n",
        "    num_grasps_to_show=64,\n",
        "    title=\"Flow Matching: 场景点云 + 预测抓取(蓝) + 目标抓取(红)\"\n",
        ")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 匹配后的抓取可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 使用matcher进行最优匹配\n",
        "from models.utils.prediction import build_pred_dict_adaptive\n",
        "from utils.hand_helper import process_hand_pose_test\n",
        "\n",
        "# 准备数据\n",
        "batch_processed = process_hand_pose_test(batch, rot_type=cfg.model.rot_type, mode=cfg.model.mode)\n",
        "\n",
        "# 构建预测字典\n",
        "pred_dict = build_pred_dict_adaptive(pred_x0)\n",
        "\n",
        "# 使用criterion的matcher进行匹配\n",
        "from models.utils.pose_processor import PoseProcessor\n",
        "\n",
        "pose_processor = PoseProcessor(hand_model, cfg.model.rot_type, cfg.model.mode)\n",
        "\n",
        "# 获取匹配\n",
        "outputs = pose_processor.get_hand_model_pose_test(pred_dict)\n",
        "assignments = model.criterion.matcher(outputs, batch_processed)\n",
        "matched_preds, matched_targets = pose_processor.get_matched_by_assignment(\n",
        "    outputs, batch_processed, assignments\n",
        ")\n",
        "\n",
        "print(\"匹配结果:\")\n",
        "print(f\"  per_query_gt_inds: {assignments['per_query_gt_inds'].shape}\")\n",
        "print(f\"  匹配的预测: {matched_preds['hand_model_pose'].shape}\")\n",
        "print(f\"  匹配的目标: {matched_targets['hand_model_pose'].shape}\")\n",
        "\n",
        "# 查看前5个匹配索引\n",
        "print(\"\\\\n前5个抓取的匹配索引:\")\n",
        "print(assignments['per_query_gt_inds'][0, :5].cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_matched_grasp_pair(scene_pc, pred_hand_pose, target_hand_pose, \n",
        "                                 hand_model, grasp_idx=0, sample_idx=0):\n",
        "    \"\"\"\n",
        "    可视化匹配后的一对抓取（预测 vs 目标）\n",
        "    \n",
        "    Args:\n",
        "        scene_pc: 场景点云 [B, N, 3]\n",
        "        pred_hand_pose: 预测手部姿态 [B, num_grasps, 23]\n",
        "        target_hand_pose: 目标手部姿态 [B, num_grasps, 23]\n",
        "        hand_model: HandModel实例\n",
        "        grasp_idx: 要可视化的抓取索引\n",
        "        sample_idx: batch中的样本索引\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # 场景点云\n",
        "    scene = scene_pc[sample_idx].cpu().numpy()\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=scene[:, 0],\n",
        "        y=scene[:, 1],\n",
        "        z=scene[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color='lightgray', opacity=0.5),\n",
        "        name='场景'\n",
        "    ))\n",
        "    \n",
        "    # 预测手部\n",
        "    pred_pose = pred_hand_pose[sample_idx, grasp_idx].unsqueeze(0)\n",
        "    pred_hand = hand_model(pred_pose, with_surface_points=True, with_meshes=True)\n",
        "    pred_points = pred_hand['surface_points'][0].cpu().numpy()\n",
        "    \n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=pred_points[:, 0],\n",
        "        y=pred_points[:, 1],\n",
        "        z=pred_points[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=3, color='blue', opacity=0.8),\n",
        "        name=f'预测抓取#{grasp_idx}'\n",
        "    ))\n",
        "    \n",
        "    # 目标手部\n",
        "    target_pose = target_hand_pose[sample_idx, grasp_idx].unsqueeze(0)\n",
        "    target_hand = hand_model(target_pose, with_surface_points=True, with_meshes=True)\n",
        "    target_points = target_hand['surface_points'][0].cpu().numpy()\n",
        "    \n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=target_points[:, 0],\n",
        "        y=target_points[:, 1],\n",
        "        z=target_points[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=3, color='red', opacity=0.8),\n",
        "        name=f'目标抓取#{grasp_idx}'\n",
        "    ))\n",
        "    \n",
        "    # 添加手腕位置连线\n",
        "    pred_wrist = pred_pose[0, :3].cpu().numpy()\n",
        "    target_wrist = target_pose[0, :3].cpu().numpy()\n",
        "    \n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=[pred_wrist[0], target_wrist[0]],\n",
        "        y=[pred_wrist[1], target_wrist[1]],\n",
        "        z=[pred_wrist[2], target_wrist[2]],\n",
        "        mode='lines+markers',\n",
        "        line=dict(color='yellow', width=5),\n",
        "        marker=dict(size=5, color='yellow'),\n",
        "        name='手腕对应'\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=f\"匹配的抓取对 #{grasp_idx}\",\n",
        "        scene=dict(\n",
        "            xaxis=dict(title='X'),\n",
        "            yaxis=dict(title='Y'),\n",
        "            zaxis=dict(title='Z'),\n",
        "            aspectmode='data'\n",
        "        ),\n",
        "        width=1000,\n",
        "        height=800\n",
        "    )\n",
        "    \n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化几个匹配对\n",
        "for grasp_idx in [0, 5, 10]:\n",
        "    fig = visualize_matched_grasp_pair(\n",
        "        batch['scene_pc'],\n",
        "        matched_preds['hand_model_pose'],\n",
        "        matched_targets['hand_model_pose'],\n",
        "        hand_model,\n",
        "        grasp_idx=grasp_idx\n",
        "    )\n",
        "    fig.show()\n",
        "    print(f\"\\\\n抓取 #{grasp_idx} 可视化完成\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 可视化2：带Mesh的抓取可视化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_hand_mesh_with_scene(scene_pc, hand_mesh, title=\"Hand Mesh\", sample_idx=0):\n",
        "    \"\"\"\n",
        "    使用trimesh可视化手部mesh和场景\n",
        "    \n",
        "    Args:\n",
        "        scene_pc: 场景点云 [N, 3]\n",
        "        hand_mesh: trimesh.Trimesh对象\n",
        "        title: 标题\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    \n",
        "    # 场景点云\n",
        "    scene = scene_pc[sample_idx].cpu().numpy()\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=scene[:, 0],\n",
        "        y=scene[:, 1],\n",
        "        z=scene[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color='gray', opacity=0.4),\n",
        "        name='场景'\n",
        "    ))\n",
        "    \n",
        "    # 手部mesh\n",
        "    vertices = hand_mesh.vertices\n",
        "    faces = hand_mesh.faces\n",
        "    \n",
        "    fig.add_trace(go.Mesh3d(\n",
        "        x=vertices[:, 0],\n",
        "        y=vertices[:, 1],\n",
        "        z=vertices[:, 2],\n",
        "        i=faces[:, 0],\n",
        "        j=faces[:, 1],\n",
        "        k=faces[:, 2],\n",
        "        color='lightblue',\n",
        "        opacity=0.8,\n",
        "        name='手部Mesh'\n",
        "    ))\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        scene=dict(\n",
        "            xaxis=dict(title='X'),\n",
        "            yaxis=dict(title='Y'),\n",
        "            zaxis=dict(title='Z'),\n",
        "            aspectmode='data'\n",
        "        ),\n",
        "        width=1000,\n",
        "        height=800\n",
        "    )\n",
        "    \n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化几个预测的手部mesh\n",
        "for i in [0, 10, 20]:\n",
        "    mesh_idx = i  # pred_meshes是扁平的列表\n",
        "    fig = visualize_hand_mesh_with_scene(\n",
        "        batch['scene_pc'],\n",
        "        pred_meshes[mesh_idx],\n",
        "        title=f\"预测抓取 #{i} - Mesh可视化\"\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 对比可视化：并排显示预测和目标\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def visualize_pred_vs_target_sidebyside(scene_pc, pred_mesh, target_mesh, \n",
        "                                         grasp_idx=0, sample_idx=0):\n",
        "    \"\"\"\n",
        "    并排对比预测和目标抓取\n",
        "    \"\"\"\n",
        "    from plotly.subplots import make_subplots\n",
        "    \n",
        "    fig = make_subplots(\n",
        "        rows=1, cols=2,\n",
        "        specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n",
        "        subplot_titles=('预测抓取', '目标抓取')\n",
        "    )\n",
        "    \n",
        "    scene = scene_pc[sample_idx].cpu().numpy()\n",
        "    \n",
        "    # 左图：预测\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=scene[:, 0], y=scene[:, 1], z=scene[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color='gray', opacity=0.3),\n",
        "        name='场景',\n",
        "        showlegend=True\n",
        "    ), row=1, col=1)\n",
        "    \n",
        "    pred_verts = pred_mesh.vertices\n",
        "    pred_faces = pred_mesh.faces\n",
        "    fig.add_trace(go.Mesh3d(\n",
        "        x=pred_verts[:, 0], y=pred_verts[:, 1], z=pred_verts[:, 2],\n",
        "        i=pred_faces[:, 0], j=pred_faces[:, 1], k=pred_faces[:, 2],\n",
        "        color='blue', opacity=0.7,\n",
        "        name='预测手部'\n",
        "    ), row=1, col=1)\n",
        "    \n",
        "    # 右图：目标\n",
        "    fig.add_trace(go.Scatter3d(\n",
        "        x=scene[:, 0], y=scene[:, 1], z=scene[:, 2],\n",
        "        mode='markers',\n",
        "        marker=dict(size=2, color='gray', opacity=0.3),\n",
        "        name='场景',\n",
        "        showlegend=False\n",
        "    ), row=1, col=2)\n",
        "    \n",
        "    target_verts = target_mesh.vertices\n",
        "    target_faces = target_mesh.faces\n",
        "    fig.add_trace(go.Mesh3d(\n",
        "        x=target_verts[:, 0], y=target_verts[:, 1], z=target_verts[:, 2],\n",
        "        i=target_faces[:, 0], j=target_faces[:, 1], k=target_faces[:, 2],\n",
        "        color='red', opacity=0.7,\n",
        "        name='目标手部'\n",
        "    ), row=1, col=2)\n",
        "    \n",
        "    fig.update_layout(\n",
        "        title=f\"匹配的抓取对 #{grasp_idx} 对比\",\n",
        "        scene=dict(aspectmode='data'),\n",
        "        scene2=dict(aspectmode='data'),\n",
        "        width=1600,\n",
        "        height=700\n",
        "    )\n",
        "    \n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 并排对比几个匹配对\n",
        "for i in [0, 5, 10]:\n",
        "    fig = visualize_pred_vs_target_sidebyside(\n",
        "        batch['scene_pc'],\n",
        "        pred_meshes[i],\n",
        "        target_meshes[i],\n",
        "        grasp_idx=i\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 统计分析：Chamfer距离\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 计算匹配后的误差统计\n",
        "from pytorch3d.loss import chamfer_distance\n",
        "\n",
        "# 生成匹配后的手部表面点\n",
        "matched_pred_hand = hand_model(\n",
        "    matched_preds['hand_model_pose'].reshape(-1, 23),\n",
        "    with_surface_points=True\n",
        ")\n",
        "matched_target_hand = hand_model(\n",
        "    matched_targets['hand_model_pose'].reshape(-1, 23),\n",
        "    with_surface_points=True\n",
        ")\n",
        "\n",
        "matched_pred_points = matched_pred_hand['surface_points'].reshape(B, num_grasps, -1, 3)\n",
        "matched_target_points = matched_target_hand['surface_points'].reshape(B, num_grasps, -1, 3)\n",
        "\n",
        "# 计算每对的Chamfer距离\n",
        "chamfer_dists = []\n",
        "for i in range(num_grasps):\n",
        "    dist = chamfer_distance(\n",
        "        matched_pred_points[:, i:i+1],\n",
        "        matched_target_points[:, i:i+1],\n",
        "        point_reduction=\"mean\"\n",
        "    )[0]\n",
        "    chamfer_dists.append(dist.item())\n",
        "\n",
        "chamfer_dists = np.array(chamfer_dists)\n",
        "\n",
        "print(\"Chamfer距离统计 (匹配后):\")\n",
        "print(f\"  平均: {chamfer_dists.mean():.4f}\")\n",
        "print(f\"  最小: {chamfer_dists.min():.4f}\")\n",
        "print(f\"  最大: {chamfer_dists.max():.4f}\")\n",
        "print(f\"  中位数: {np.median(chamfer_dists):.4f}\")\n",
        "print(f\"  标准差: {chamfer_dists.std():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 绘制Chamfer距离分布直方图\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(\n",
        "    x=chamfer_dists,\n",
        "    nbinsx=30,\n",
        "    name='Chamfer Distance',\n",
        "    marker_color='blue'\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"匹配后Chamfer距离分布\",\n",
        "    xaxis_title=\"Chamfer Distance\",\n",
        "    yaxis_title=\"Count\",\n",
        "    width=800,\n",
        "    height=400\n",
        ")\n",
        "\n",
        "fig.show()\n",
        "\n",
        "# 显示最好和最差的抓取索引\n",
        "best_idx = chamfer_dists.argmin()\n",
        "worst_idx = chamfer_dists.argmax()\n",
        "\n",
        "print(f\"\\\\n最佳抓取: #{best_idx}, Chamfer={chamfer_dists[best_idx]:.4f}\")\n",
        "print(f\"最差抓取: #{worst_idx}, Chamfer={chamfer_dists[worst_idx]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化最佳和最差的匹配对\n",
        "print(\"\\\\n=== 最佳匹配抓取 ===\")\n",
        "fig_best = visualize_matched_grasp_pair(\n",
        "    batch['scene_pc'],\n",
        "    matched_preds['hand_model_pose'],\n",
        "    matched_targets['hand_model_pose'],\n",
        "    hand_model,\n",
        "    grasp_idx=best_idx\n",
        ")\n",
        "fig_best.show()\n",
        "\n",
        "print(\"\\\\n=== 最差匹配抓取 ===\")\n",
        "fig_worst = visualize_matched_grasp_pair(\n",
        "    batch['scene_pc'],\n",
        "    matched_preds['hand_model_pose'],\n",
        "    matched_targets['hand_model_pose'],\n",
        "    hand_model,\n",
        "    grasp_idx=worst_idx\n",
        ")\n",
        "fig_worst.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. 姿态误差分析\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 分解姿态并计算各部分误差\n",
        "matched_pred_pose = matched_preds['hand_model_pose'][0]  # [num_grasps, 23]\n",
        "matched_target_pose = matched_targets['hand_model_pose'][0]  # [num_grasps, 23]\n",
        "\n",
        "# 提取各部分\n",
        "pred_trans = matched_pred_pose[:, :3]\n",
        "pred_qpos = matched_pred_pose[:, 3:19]\n",
        "pred_rot = matched_pred_pose[:, 19:23]\n",
        "\n",
        "target_trans = matched_target_pose[:, :3]\n",
        "target_qpos = matched_target_pose[:, 3:19]\n",
        "target_rot = matched_target_pose[:, 19:23]\n",
        "\n",
        "# 计算误差\n",
        "trans_error = torch.norm(pred_trans - target_trans, dim=-1).cpu().numpy()\n",
        "qpos_error = torch.norm(pred_qpos - target_qpos, dim=-1).cpu().numpy()\n",
        "\n",
        "# 旋转误差（四元数）\n",
        "from pytorch3d.transforms import quaternion_to_matrix\n",
        "pred_rot_mat = quaternion_to_matrix(pred_rot)\n",
        "target_rot_mat = quaternion_to_matrix(target_rot)\n",
        "R_diff = torch.bmm(pred_rot_mat.transpose(-2, -1), target_rot_mat)\n",
        "trace = R_diff.diagonal(dim1=-2, dim2=-1).sum(-1)\n",
        "rot_error = torch.acos(torch.clamp((trace - 1) / 2, -1, 1)).cpu().numpy() * 180 / np.pi\n",
        "\n",
        "print(\"姿态误差统计:\")\n",
        "print(f\"\\\\n平移误差 (m):\")\n",
        "print(f\"  平均: {trans_error.mean():.4f}\")\n",
        "print(f\"  中位数: {np.median(trans_error):.4f}\")\n",
        "print(f\"  最大: {trans_error.max():.4f}\")\n",
        "\n",
        "print(f\"\\\\n旋转误差 (度):\")\n",
        "print(f\"  平均: {rot_error.mean():.4f}\")\n",
        "print(f\"  中位数: {np.median(rot_error):.4f}\")\n",
        "print(f\"  最大: {rot_error.max():.4f}\")\n",
        "\n",
        "print(f\"\\\\n关节角误差:\")\n",
        "print(f\"  平均: {qpos_error.mean():.4f}\")\n",
        "print(f\"  中位数: {np.median(qpos_error):.4f}\")\n",
        "print(f\"  最大: {qpos_error.max():.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 绘制误差分布\n",
        "fig = make_subplots(\n",
        "    rows=1, cols=3,\n",
        "    subplot_titles=('平移误差分布', '旋转误差分布', '关节角误差分布')\n",
        ")\n",
        "\n",
        "fig.add_trace(go.Histogram(x=trans_error, nbinsx=20, name='平移', marker_color='blue'), row=1, col=1)\n",
        "fig.add_trace(go.Histogram(x=rot_error, nbinsx=20, name='旋转', marker_color='green'), row=1, col=2)\n",
        "fig.add_trace(go.Histogram(x=qpos_error, nbinsx=20, name='关节角', marker_color='red'), row=1, col=3)\n",
        "\n",
        "fig.update_layout(\n",
        "    title=\"匹配后姿态误差分布\",\n",
        "    width=1400,\n",
        "    height=400,\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. 批量可视化（多个样本）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 可视化多个样本的抓取质量\n",
        "num_samples_to_vis = 5\n",
        "all_chamfer_dists = []\n",
        "\n",
        "for batch_idx, batch_sample in enumerate(val_loader):\n",
        "    if batch_idx >= num_samples_to_vis:\n",
        "        break\n",
        "    \n",
        "    # 移动到device\n",
        "    for key in batch_sample:\n",
        "        if isinstance(batch_sample[key], torch.Tensor):\n",
        "            batch_sample[key] = batch_sample[key].to(DEVICE)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # 采样\n",
        "        pred_x0_sample = model.sample(batch_sample, k=1)\n",
        "        \n",
        "        # 生成手部点云\n",
        "        pred_pose_sample = denorm_hand_pose_robust(pred_x0_sample, cfg.model.rot_type, cfg.model.mode)\n",
        "        pred_hand = hand_model(\n",
        "            pred_pose_sample.reshape(-1, 23),\n",
        "            with_surface_points=True\n",
        "        )\n",
        "        \n",
        "        target_hand = hand_model(\n",
        "            batch_sample['hand_model_pose'].reshape(-1, 23),\n",
        "            with_surface_points=True\n",
        "        )\n",
        "        \n",
        "        # 计算Chamfer\n",
        "        pred_pts = pred_hand['surface_points'].reshape(BATCH_SIZE, NUM_GRASPS, -1, 3)\n",
        "        target_pts = target_hand['surface_points'].reshape(BATCH_SIZE, NUM_GRASPS, -1, 3)\n",
        "        \n",
        "        chamfer = chamfer_distance(\n",
        "            pred_pts,\n",
        "            target_pts,\n",
        "            point_reduction=\"sum\",\n",
        "            batch_reduction=\"mean\"\n",
        "        )[0]\n",
        "        \n",
        "        all_chamfer_dists.append(chamfer.item())\n",
        "    \n",
        "    print(f\"Sample {batch_idx}: Chamfer={chamfer.item():.2f}\")\n",
        "\n",
        "print(f\"\\\\n{num_samples_to_vis}个样本的平均Chamfer距离: {np.mean(all_chamfer_dists):.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. 保存可视化结果\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
